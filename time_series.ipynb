{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1756445342528,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "Zc0xvqCblXPq",
    "outputId": "6fbb9c83-6f7a-4c41-b321-00a05d79da69"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'Tesla T4')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available(), torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28920,
     "status": "ok",
     "timestamp": 1756445371450,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "v5vytfkt75Rx",
    "outputId": "1490e4fc-fc91-40b6-ed28-5ba77913f1e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/DLAA_2025\n",
      "check_training.ipynb  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/                        time_series.ipynb\n",
      "dataset.jsonl         \u001b[01;34mqwen2.5-0.5b-instruct-lora-output\u001b[0m/  ts_check_training.py\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd \"/content/drive/My Drive/DLAA_2025\"\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1756445372401,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "DjVyq16QctDy",
    "outputId": "ab1f684b-0cdb-464f-f8c9-bb8119684fc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"index\": 0, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [00, 01, 00, 05, 07, 06, 09, 08, 10, 10, 12, 13, 16, 16, 17, 17, 15, 14, 14, 16, 18, 18, 19, 22, 26, 29, 26, 25, 24, 25, 24, 24, 26, 24, 24, 25, 27, 28, 26, 24, 26, 31, 30, 30, 30, 33, 34, 32, 33, 35, 35, 40, 41, 41, 44, 45, 45, 48, 48, 51, 49, 51, 53, 55, 54, 56, 59, 60, 57, 57, 58, 58, 60, 59, 60, 62, 61, 60, 60, 59, 59, 62, 65, 65, 63, 64, 63, 65, 68, 70, 74, 69, 71, 70, 70, 69, 70, 66, 69, 70, 69, 70, 72, 72, 74, 74, 74, 76, 76, 79, 79, 78, 79, 78, 80, 81, 82, 87, 90, 90, 92, 92, 90, 91, 92, 95, 95, 99]\", \"output\": \"{\\\"trend\\\": \\\"The time series shows an overall increasing trend.\\\", \\\"noise\\\": \\\"The noise intensity is medium.\\\", \\\"extrema\\\": \\\"The global maximum is located towards the end, and the global minimum is located at the beginning.\\\"}\"}\n",
      "{\"index\": 1, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [38, 46, 58, 66, 65, 71, 63, 60, 57, 51, 51, 54, 56, 49, 48, 43, 38, 32, 35, 31, 33, 33, 32, 26, 31, 37, 36, 30, 23, 24, 17, 10, 15, 22, 24, 26, 19, 20, 20, 10, 08, 11, 17, 14, 06, 10, 07, 08, 06, 03, 03, 07, 02, 00, 04, 06, 02, 02, 04, 00, 03, 04, 07, 11, 02, 02, 08, 16, 20, 23, 20, 07, 14, 19, 18, 21, 29, 26, 39, 38, 45, 43, 38, 37, 34, 32, 35, 44, 21, 31, 32, 38, 45, 36, 37, 37, 35, 38, 57, 64, 64, 64, 64, 72, 75, 80, 89, 99, 97, 96, 99, 90, 87, 85, 87, 84, 83, 83, 85, 80, 81, 87, 75, 78, 82, 85, 81, 83]\", \"output\": \"{\\\"trend\\\": \\\"The time series exhibits an overall increasing trend from the beginning to the end.\\\", \\\"noise\\\": \\\"The noise intensity is medium, with noticeable fluctuations throughout the series.\\\", \\\"extrema\\\": \\\"The global maximum is located at the end, while the global minimum is situated in the middle of the time series.\\\"}\"}\n",
      "{\"index\": 2, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [50, 63, 61, 69, 56, 43, 40, 45, 43, 40, 32, 32, 31, 30, 35, 36, 32, 32, 39, 43, 36, 29, 32, 27, 36, 29, 40, 46, 38, 37, 35, 38, 37, 34, 32, 32, 23, 24, 21, 09, 18, 12, 04, 12, 19, 33, 31, 32, 33, 29, 29, 33, 37, 37, 26, 26, 21, 21, 26, 41, 41, 43, 37, 43, 35, 38, 27, 19, 17, 26, 21, 26, 17, 20, 19, 19, 20, 16, 10, 04, 01, 00, 06, 11, 26, 43, 40, 47, 41, 36, 33, 30, 44, 44, 36, 47, 40, 35, 31, 33, 30, 32, 32, 37, 34, 27, 29, 46, 60, 62, 73, 71, 74, 70, 68, 77, 73, 76, 78, 75, 91, 97, 96, 93, 96, 88, 87, 99]\", \"output\": \"{\\\"trend\\\": \\\"The time series shows an increasing trend over the observed period.\\\", \\\"noise\\\": \\\"The noise intensity is high, with significant fluctuations throughout the series.\\\", \\\"extrema\\\": \\\"The global maximum is located towards the end, and the global minimum is located towards the middle of the series.\\\"}\"}\n",
      "{\"index\": 3, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [14, 12, 06, 06, 00, 00, 04, 06, 06, 10, 11, 13, 19, 22, 24, 23, 22, 27, 30, 30, 32, 36, 32, 34, 46, 46, 51, 54, 58, 56, 57, 56, 61, 61, 56, 55, 54, 53, 50, 49, 50, 52, 53, 54, 57, 58, 57, 64, 68, 65, 63, 59, 58, 60, 57, 60, 60, 60, 59, 58, 59, 62, 58, 63, 66, 63, 66, 66, 70, 70, 65, 59, 58, 50, 52, 53, 58, 66, 71, 73, 80, 80, 77, 81, 84, 88, 91, 86, 87, 87, 92, 96, 91, 99, 91, 89, 93, 91, 94, 92, 86, 83, 91, 85, 93, 87, 91, 86, 88, 87, 92, 88, 97, 97, 97, 92, 91, 86, 87, 82, 84, 84, 88, 95, 90, 88, 89, 88]\", \"output\": \"{\\\"trend\\\": \\\"The time series exhibits an overall increasing trend, especially noticeable in the first half.\\\", \\\"noise\\\": \\\"The noise intensity in this time series is medium with moderate fluctuations throughout the entire period.\\\", \\\"extrema\\\": \\\"The global maximum is located towards the end of the time series, while the global minimum is situated at the beginning.\\\"}\"}\n",
      "{\"index\": 4, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [05, 10, 05, 10, 10, 09, 09, 09, 11, 12, 11, 09, 10, 10, 14, 10, 05, 05, 05, 00, 02, 06, 05, 07, 04, 08, 11, 10, 06, 10, 12, 14, 19, 18, 18, 13, 13, 15, 20, 24, 29, 28, 26, 25, 25, 26, 28, 28, 29, 28, 28, 30, 31, 33, 32, 30, 31, 25, 22, 22, 21, 19, 19, 24, 28, 27, 30, 25, 22, 22, 24, 21, 26, 24, 29, 35, 30, 30, 32, 32, 33, 38, 34, 32, 38, 45, 49, 48, 55, 60, 63, 63, 64, 62, 67, 71, 67, 69, 69, 70, 75, 76, 73, 76, 80, 84, 81, 74, 74, 77, 82, 84, 87, 87, 89, 94, 99, 96, 94, 95, 93, 91, 92, 85, 81, 83, 84, 84]\", \"output\": \"{\\\"trend\\\": \\\"The time series exhibits an overall increasing trend.\\\", \\\"noise\\\": \\\"The noise intensity is medium.\\\", \\\"extrema\\\": \\\"The global maximum is located towards the end, while the global minimum is located at the beginning.\\\"}\"}\n",
      "{\"index\": 5, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [01, 04, 00, 03, 07, 06, 08, 07, 07, 04, 05, 10, 10, 10, 11, 14, 11, 12, 12, 16, 16, 15, 13, 15, 17, 21, 22, 20, 19, 20, 20, 18, 15, 14, 19, 26, 30, 33, 38, 38, 36, 42, 40, 37, 36, 40, 42, 34, 22, 25, 21, 28, 24, 24, 24, 24, 25, 24, 26, 30, 36, 35, 35, 40, 46, 44, 45, 45, 45, 48, 44, 44, 47, 44, 42, 38, 40, 45, 50, 53, 59, 62, 61, 59, 62, 68, 66, 71, 70, 67, 66, 67, 68, 74, 73, 69, 70, 76, 76, 75, 88, 90, 94, 86, 83, 86, 89, 85, 86, 83, 86, 86, 89, 93, 91, 88, 95, 99, 97, 95, 99, 94, 89, 90, 94, 96, 88, 87]\", \"output\": \"{\\\"trend\\\": \\\"The time series exhibits an overall increasing trend over the observed period.\\\", \\\"noise\\\": \\\"The noise intensity in this time series is medium, with noticeable fluctuations around the trend.\\\", \\\"extrema\\\": \\\"The global maximum occurs towards the end of the series, while the global minimum is located at the beginning.\\\"}\"}\n",
      "{\"index\": 6, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [61, 62, 63, 54, 53, 56, 58, 55, 60, 71, 66, 62, 61, 69, 61, 66, 73, 68, 68, 68, 71, 79, 82, 85, 83, 88, 84, 84, 80, 77, 81, 88, 91, 99, 98, 92, 86, 79, 72, 60, 60, 64, 67, 60, 53, 49, 39, 40, 50, 49, 45, 44, 50, 55, 56, 56, 52, 46, 36, 37, 31, 33, 32, 35, 36, 43, 40, 46, 40, 36, 34, 28, 28, 29, 28, 31, 27, 22, 18, 17, 05, 07, 13, 05, 00, 07, 09, 13, 17, 17, 13, 12, 05, 01, 07, 11, 12, 20, 25, 31, 17, 20, 17, 19, 15, 20, 19, 19, 23, 30, 30, 37, 40, 34, 33, 37, 45, 42, 33, 40, 43, 40, 40, 30, 33, 34, 23, 22]\", \"output\": \"{\\\"trend\\\": \\\"The time series exhibits a decreasing trend over the observed period.\\\", \\\"noise\\\": \\\"The noise intensity in the time series is medium, with noticeable fluctuations throughout.\\\", \\\"extrema\\\": \\\"The maximum is reached around the middle of the time series and the minimum is reached around the middle of the time series.\\\"}\"}\n",
      "{\"index\": 7, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [00, 01, 01, 08, 10, 08, 08, 09, 10, 12, 16, 17, 19, 19, 21, 21, 21, 23, 24, 27, 31, 32, 31, 29, 31, 33, 34, 37, 38, 39, 39, 40, 43, 42, 44, 46, 48, 48, 48, 47, 47, 45, 43, 42, 43, 42, 43, 43, 43, 43, 45, 48, 48, 49, 48, 51, 53, 56, 53, 55, 53, 56, 57, 57, 58, 59, 59, 61, 61, 63, 64, 66, 66, 67, 68, 67, 68, 69, 70, 73, 74, 75, 75, 75, 75, 74, 76, 76, 74, 75, 76, 75, 76, 77, 73, 71, 70, 73, 75, 75, 75, 73, 77, 82, 83, 84, 86, 87, 88, 88, 89, 93, 92, 94, 93, 93, 92, 93, 91, 96, 99, 99, 98, 98, 97, 95, 94, 94]\", \"output\": \"{\\\"trend\\\": \\\"The time series shows a generally increasing trend over the observed period.\\\", \\\"noise\\\": \\\"The noise intensity is relatively low to medium, with some noticeable fluctuations throughout.\\\", \\\"extrema\\\": \\\"The global maximum appears towards the end of the time series, while the global minimum is located at the beginning.\\\"}\"}\n",
      "{\"index\": 8, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [00, 00, 04, 07, 10, 12, 13, 14, 16, 16, 16, 19, 20, 24, 28, 28, 29, 30, 33, 35, 34, 37, 39, 41, 40, 43, 44, 46, 48, 51, 50, 49, 48, 51, 50, 51, 50, 53, 51, 50, 50, 54, 53, 54, 53, 57, 57, 56, 56, 60, 59, 60, 60, 60, 60, 61, 61, 58, 63, 61, 62, 63, 64, 67, 69, 67, 68, 71, 74, 75, 77, 80, 80, 80, 82, 80, 82, 82, 84, 85, 83, 82, 84, 84, 85, 86, 87, 89, 89, 89, 91, 90, 90, 88, 86, 87, 88, 87, 88, 89, 91, 91, 92, 91, 90, 89, 87, 88, 90, 92, 92, 95, 94, 91, 92, 94, 96, 97, 97, 97, 96, 97, 99, 99, 97, 99, 99, 99]\", \"output\": \"{\\\"trend\\\": \\\"The time series exhibits an increasing trend over time.\\\", \\\"noise\\\": \\\"The noise intensity in the time series is relatively medium, with noticeable fluctuations throughout.\\\", \\\"extrema\\\": \\\"The global maximum is located towards the end of the time series, while the global minimum is situated at the beginning.\\\"}\"}\n",
      "{\"index\": 9, \"input\": \"\\n/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\\nPut the description in a JSON format with the following pattern\\n```json\\n{ \\\"trend\\\": <sentence1>,\\n  \\\"noise\\\": <sentence2>,\\n  \\\"extrema\\\": <sentence3> }\\n```\\n Series: [01, 00, 02, 04, 02, 01, 05, 09, 06, 04, 10, 11, 12, 16, 16, 13, 16, 16, 14, 19, 20, 23, 25, 23, 26, 28, 28, 27, 30, 34, 39, 37, 37, 37, 38, 41, 41, 43, 43, 42, 44, 51, 53, 50, 52, 53, 54, 53, 54, 56, 57, 58, 62, 63, 61, 61, 60, 62, 66, 66, 67, 67, 68, 71, 72, 71, 67, 68, 69, 69, 71, 72, 68, 69, 69, 70, 70, 74, 78, 81, 83, 86, 85, 85, 84, 82, 77, 80, 81, 82, 82, 80, 80, 85, 84, 87, 90, 88, 91, 93, 97, 97, 99, 97, 91, 92, 88, 86, 84, 84, 80, 76, 77, 74, 78, 80, 82, 84, 85, 83, 86, 89, 92, 91, 91, 93, 97, 99]\", \"output\": \"{\\\"trend\\\": \\\"The time series exhibits an overall increasing trend.\\\", \\\"noise\\\": \\\"The noise intensity is medium, with noticeable fluctuations throughout.\\\", \\\"extrema\\\": \\\"The global maximum is approximately located towards the end, while the global minimum is at the beginning.\\\"}\"}\n"
     ]
    }
   ],
   "source": [
    "!head dataset.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1756445372415,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "Aqpd8bL6eOsM"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainerCallback\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1756445372436,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "menM8MoQediX",
    "outputId": "1ffff801-29aa-4bda-ec28-575623d0d61f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training outputs saved in: ./qwen2.5-0.5b-instruct-lora-output\n"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "DATASET_PATH = \"dataset.jsonl\"\n",
    "\n",
    "# Extract short model name\n",
    "model_name_parts = MODEL_NAME.split('/')\n",
    "model_short_name = model_name_parts[-1] if model_name_parts else \"unknown_model\"\n",
    "OUTPUT_DIR = f\"./{model_short_name.lower()}-lora-output\"\n",
    "\n",
    "print(\"Training outputs saved in:\", OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1756445372449,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "_rXcpTdPetOY",
    "outputId": "1ea43e3a-7684-448a-fcf2-97caa639fbed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 45\n",
      "Test size: 5\n"
     ]
    }
   ],
   "source": [
    "# === LOAD JSONL DATASET ===\n",
    "def load_jsonl_dataset(path):\n",
    "    with open(path, 'r') as f:\n",
    "        lines = [json.loads(l) for l in f]\n",
    "    return Dataset.from_list(lines)\n",
    "\n",
    "raw_dataset = load_jsonl_dataset(DATASET_PATH)\n",
    "# only keep nb_samples first samples\n",
    "nb_samples = 50\n",
    "raw_dataset = raw_dataset.select(range(nb_samples)) ###########################################\n",
    "split_dataset = raw_dataset.train_test_split(test_size=0.10)\n",
    "dataset = DatasetDict({\n",
    "    \"train\": split_dataset[\"train\"],\n",
    "    \"test\": split_dataset[\"test\"]\n",
    "})\n",
    "\n",
    "print(f\"Train size: {len(dataset['train'])}\")\n",
    "print(f\"Test size: {len(dataset['test'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249,
     "referenced_widgets": [
      "e8b5bfc8776c49428114a563494bd3e8",
      "2a21bebd4bd94f229c3e0437a5cb876c",
      "79446a9a789e479a92e794fe8afa1937",
      "dc053a6bd17d44ab8cad90d4d11cbe73",
      "5552e61edb8f45e9af00f10309e2e5e4",
      "1e7e3dc37eea4bc6beca5f889121fc71",
      "4a68c4f0e9754aa1ac1ba521159265c8",
      "87c7d18e990b4164919457c1f53270ea",
      "3debdce50cde4634a69caf40766e7e5b",
      "834e735affa444b1a274ae24a62be640",
      "6fb54e8f67de415a94493829af02e004",
      "39074d8a6d3243cea83addcfd73a159a",
      "d7d290d7a7754b869314f8a1b929a905",
      "5dffb410d5a343d587607961eecd1bb0",
      "7599d015f44043ae952210ca635801a0",
      "12619e16c5844930b95563b9258a2d52",
      "574dba3318df453f883e653c410334dd",
      "49b8d28ffa514abe8a95c7d0639a52e5",
      "25228bceca694ae0a8514d4fbb340561",
      "36b9074044154693b7fbb2dc2ce01830",
      "0a59ddb001ae4d9c98b3fdf054cee68a",
      "94047336d6f44a03bc1c70f304d1bd8c",
      "401d8c9a5362418cba730562f0e75473",
      "7a58cec4617144f6b0a5e4650e6a4658",
      "0d02e452ee0c4796aa76584ed745696c",
      "960ed7fb56df4a348d941f9035eb315e",
      "0a418174b16a49e9adc70e444d4f293a",
      "6ae033e445fc45958b1119dc260ebe92",
      "4b756afd0cef4f02910c21b706c9273d",
      "4d58d78fbcb946f68f7f501b92df34ad",
      "50cacc868c994019907eb0340c5ffce4",
      "16c6ce52234e43f8a99b72c18a55f1a8",
      "7eec244aa5024457be3e1e2ff3f364a7",
      "fbffb0d5e82c43c0b670daf3590fbd0d",
      "5ee934f0d08e4523a3fd8294f8db3c92",
      "d825dfae52b24098923c31a42ef5963c",
      "1a046e859b7145dc97211bb0ee74a9cb",
      "02cc43b6c9a74b05aa65ab8d4b3e8db5",
      "8e688522af944d398991a9526eba4d5d",
      "959d5c8be4c54f45a6f49a403968a0a8",
      "2672196916ae466c9c7fc3de48dca5b8",
      "4240c8d824f84f0d9c1782e2594da497",
      "64fdc754dd6547e998758fabba1a7804",
      "b78c3cbbacd24e4ea9a194ec1c0a2432"
     ]
    },
    "executionInfo": {
     "elapsed": 3133,
     "status": "ok",
     "timestamp": 1756445375583,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "YrT4gRzRe3RH",
    "outputId": "62393463-e4de-485a-9a07-2fb45118f6c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8b5bfc8776c49428114a563494bd3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39074d8a6d3243cea83addcfd73a159a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "401d8c9a5362418cba730562f0e75473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbffb0d5e82c43c0b670daf3590fbd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === TOKENIZER ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
    "####### xxxxx tokenizer.pad_token = tokenizer.eos_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "d7bbc7bdea7a42d49149ccd751413775",
      "d087ad0c78ee4ee39b0579880ec0a68f",
      "d6a8c1d9c6f643a4bd20507a694c43ff",
      "8acfd45d09204333b3867da4655f4d71",
      "e5726ecc71cf4a5481c65edb6be32b19",
      "d358406b98594ec9abd811696edb76a8",
      "8b97249c80e044daa41d40903ccccd3e",
      "b8113f755b344daf90d547fb29f65f3a",
      "a3fc6dc01dc64b9c8e88a9c4298ce334",
      "8ef1c28ae5b541c39c157c4fc9af5f6b",
      "950b8cdcb63b4e569e50a77ddc37e3a8",
      "fbea94177da146e183814d34e931e348",
      "5f42660f3efb4caa899062e6f1cea35b",
      "161b8185eab34c7098077d9a90ba5602",
      "6134778b68d44d87bba5152c8e0469e4",
      "be80089224d04d0e806893245bfb8e1d",
      "8504fee40e6e4ff5a32521f3a7db542e",
      "7c7c695352cf40c086978c02037d4a49",
      "a952b5248808426fafd6b6d456271040",
      "0023fc629c5548a2a76438a977a75951",
      "44d55e6755a745a98fb9d9a3c4e6b1fc",
      "17b7a15135aa4deb8b31be6af060a3cd"
     ]
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1756445375957,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "rIUVUNImfJKI",
    "outputId": "4267eb18-4c78-405d-acc3-3e5141978abf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bbc7bdea7a42d49149ccd751413775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/45 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbea94177da146e183814d34e931e348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete.\n"
     ]
    }
   ],
   "source": [
    "# === PREPROCESSING ===\n",
    "def tokenize(example):\n",
    "    prompt = example[\"input\"]\n",
    "    response = example[\"output\"]\n",
    "\n",
    "    # Tokenize prompt and response separately\n",
    "    prompt_ids = tokenizer(prompt, truncation=False)[\"input_ids\"]\n",
    "    response_ids = tokenizer(response, truncation=True, max_length=256)[\"input_ids\"]\n",
    "\n",
    "    # Calculate available space for the prompt\n",
    "    max_total_len = 1024\n",
    "    max_prompt_len = max_total_len - len(response_ids)\n",
    "    prompt_ids = prompt_ids[-max_prompt_len:]  # Truncate if too long\n",
    "\n",
    "    input_ids = prompt_ids + response_ids\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Labels: ignore prompt tokens\n",
    "    labels = [-100] * len(prompt_ids) + response_ids\n",
    "\n",
    "    # Padding if necessary\n",
    "    pad_len = max_total_len - len(input_ids)\n",
    "    if pad_len > 0:\n",
    "        input_ids += [tokenizer.pad_token_id] * pad_len\n",
    "        attention_mask += [0] * pad_len\n",
    "        labels += [-100] * pad_len\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "print(\"Tokenizing data...\")\n",
    "tokenized_dataset = dataset.map(tokenize, remove_columns=dataset[\"train\"].column_names)\n",
    "print(\"Tokenization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "4e31fd88062a478ebdcf4394106d4a86",
      "5098db57dec74038a6cc35ac8d217847",
      "d670fcf21603477b9b85a9786434094e",
      "c094513627e144b9b3dfb41e2ef84781",
      "b3eef861d54e4a1a8cfb254d959a117c",
      "18dadc1e3a264a85ba98011608030cbd",
      "da9564e039e74c9d94d0b206a3d64018",
      "94c93d123b324a3c816db8b7d2d49b6c",
      "7b5ea19d2d8c4fc9a3ca187ed4f5fb8a",
      "dd429220ee674e41bdc1959f2d3fe702",
      "4b74cf67588c414eb3e7ff74d1ad5d87",
      "166f2ff3a06244da90cbaae06c50b5e8",
      "14ea8050439d4bf09ab0ff0884418555",
      "71e00806055941c4b89ea90e105aeff3",
      "3668d85207934510801000b7f92d48fd",
      "4d4f92a6f02547bf9a8c4042f56ecd46",
      "e47d8fb071ff4fc9814850692b92b891",
      "0ae0ffa890fd4d8e8164289b0d3b4fd0",
      "d170a6cc7b714e818d1ec6545ade38f3",
      "b36fb3815c29441fb62051099ed90a11",
      "6cc342507f45420e84c5769f81e9c5e9",
      "aa662c1cc877459aaeba8721c47a8678",
      "48c5253d19264cb08e59b5a3d19816b5",
      "6d15e1465bf44cc8b57699e35e1e799e",
      "4164dd0ad5d84392957109c2ff56416b",
      "b5e26c8986fb4a3a825d54d61f4ef89b",
      "805f8ccfe4764550903ce5d2bcb6f14a",
      "d8f153679aed496e90c22ae41cb46372",
      "a8923e222d6c410692f527864c2bf3e6",
      "33e278dfeffb476980f7ae1d2977a441",
      "e760171669b14b45acdea82d7d8a08cd",
      "505d3f26f5d34536b7c5bcf027f00a9b",
      "46e86fd809b94990935f51b52430ae22"
     ]
    },
    "executionInfo": {
     "elapsed": 19494,
     "status": "ok",
     "timestamp": 1756445395449,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "xiyxS7DRfYJS",
    "outputId": "4ead3b1e-6969-4e12-b687-d3ff05aeb681"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e31fd88062a478ebdcf4394106d4a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166f2ff3a06244da90cbaae06c50b5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c5253d19264cb08e59b5a3d19816b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === MODEL ===\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1756445395512,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "fmK75ZjGmcK6"
   },
   "outputs": [],
   "source": [
    "# === CONFIGURATION LORA ===\n",
    "lora_config = LoraConfig(\n",
    "    r=4,  # r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "b86dc60775434c688cc5d6516202c478",
      "6cfe67375ab84f22b0a6cc647c8972e6",
      "778fa9010fe44bc78dde971336797c28",
      "0849a54b19524154a3050367ae61c6d6",
      "01f5150a10614f60a284339ec91dab17",
      "3c64e220878a488a9b7838292c77be2c",
      "fcc6812a7bcb44b9ae46d062beeaed2e",
      "6866396a97724572adb4be5677dbf25d",
      "f3f8f35bc9504d828e72f8d1c5e7ef22",
      "4e34d0a9020e49e1972d31808042a665",
      "1de2f6491b1d41808b1b3042aa452872",
      "59f9c4c0b3da439eaa0aefde8572e050",
      "9b4c6c38564f4b6da4e2dd2c793969aa",
      "3e5c040750714e9294d901838b9b0861",
      "34d375bb28e74777b098efbcf55e127a",
      "27710e9ae1cf471480b61c7427abb21b",
      "a052e56f58da4822a0c6e4ae510d1302",
      "d9271c80fa734d7d96f600595dc4d8be",
      "6a89fc0d795c4e768567204c93a6bbd6",
      "067f66585da3449fb13a1ffb3b41a98c",
      "a262d4e78754442b8aa012e60b90b0d4",
      "a199ad182849441aa711d55f6a2fded5",
      "e24206ffc96e47b89fd72efae771f6fb",
      "f6ff24291ced44f095a27825a8a92dcb",
      "2c7e1022d2764dff95236e8bee84d558",
      "168b67023d534163973112349ee94f23",
      "1468e58279b84e18b2b4afebc37ac1a1",
      "d7b27f4d145844f0b057bff1cf75b5ad",
      "837cc5941db64177af9f9a17e541049a",
      "d476a0e4e77e4724b903a3d432eb4c4d",
      "75fb330ca2aa4a08bfbd8a8604a410da",
      "d68b331e879a4dbea53e70f3379c56ae",
      "e15329275a8b4460b646c305254b3e86",
      "e4bdb2c967894e4faebda24adebb36ac",
      "b012eafb3da84e63acd117d9a8d72e13",
      "196bafe826e245bab757254fc6c558b2",
      "20d69b8697af4010a1a2f28f492aa12e",
      "da46fcae42c94a458f841454d0ca2f4e",
      "82a3a1006f9248daa7584a222cb964bc",
      "77bbae5e02f946ba93fef1dff72db498",
      "a2e91f1fbd564fd1b23257641ba0ac79",
      "2939562b918143bb845aa4cd76ba9590",
      "3814e2fa50944d598ab52424b4ccd806",
      "1f3d857a1b484799b6d3219fe49df17c",
      "0b702c2cf5bb40fba95c5767cc7095cd",
      "dd24a28225864e67a0a1da12e02211f0",
      "b469be59bfff4957a0521c9a22fe792a",
      "58b3ceaad41944278d53c99eb0751fc6",
      "ed3ab784693148caa3a73114759fef40",
      "fbec5b46d1224407aa24c4bd9ea51e69",
      "8051b62e2137417bb09f56d95f49ab67",
      "56f69c8177b548e98e444796590cfbce",
      "e116e31150484eb28dc20b2c42b90629",
      "ea013d382d7243b3b825e810a5028513",
      "a04972dee6c947c6b60d91808ffd51b8",
      "d9b5943ade704016888546cd3808a570",
      "daebb680b15347148b0a9dd885570242",
      "73280757440444d2a727a6aeb73b17ff",
      "725a0f706ca14147ab493da5059311c2",
      "88bfd397c8e8432f83df888f5565130e",
      "f32115b6158e493f8f2abebb546af13d",
      "2b610d58c75d47dd9494d048c61e9ab0",
      "c88d0146d1434223aa4a299babda5804",
      "4e1af365a2544a58828eb35350734289",
      "22c4b0cf14ed469187adbe7961dcd6c9",
      "e50a3207f56e460d81e0c8179f54d7a8",
      "e009c6ef14ca4ba9b96aa5f35a74ef52",
      "6ecd9850918b4b44b0ca3c592a24ed70",
      "f2b34425d2fe404cb4201f3727fe6ab5",
      "c7c70cd409d3472e9b4223813d4f46c4",
      "ae982b3ebdc64f02aeaf9d8fee45e342",
      "4c8f2e3815df4846bc4f28833d278ac5",
      "25a638a893a14c48816447fcd3c8b3d6",
      "727313cf7907429c90774d0634c30e84",
      "bb5c15deb95b4432a861ca062ea82b82",
      "5ec4bc467a564998a22e4addac7df191",
      "df6d84a0de8c48558d77ab94376ef944",
      "02df5c4dbaab4992a113f135da53fee5",
      "8a57147c2bbd4f2ea3dd79a3a649faf9",
      "08839cdfceee46eca1cbea8e15b0a0f8",
      "85e4eda0de0b45d48a8347ad1623beb2",
      "f9759ff7f982410bac72524a7884e2f0",
      "8a9304c6727d41828fc53776a8d761ea",
      "554261a629924ff1b8d4e83c2e74cb69",
      "d1520c5d7e1147a69d104aa805348150",
      "8e4fb022849a4982b5d3a3df805150a2",
      "793001546f544cd7a473fa3c4816193e",
      "a6837355dfba46e0ad05480d13ab9f24",
      "62f8a9d2c1cf4e3f8511121ae6f81e41",
      "a23f10b925ab44adb1fba38f1e1e0e39",
      "ab882eeec97e4d36bdf027cbf3548b87",
      "96c5c7976b434a7ebc2b01cf6f0a0714",
      "5ce4c9965bd144d7bf9916a78adda655",
      "bdb9c92ba7454d2fb67bda5ea4151be4",
      "2c69e952775a4eebac5560ecc25510a8",
      "c007145eadc84e519150707f6c7f039e",
      "8b6df40043f94fff94a67f7ec031869f",
      "a12026a4b4b3475683d5104dbae79064",
      "2d526b47cfb341659abc47bea0af6c52",
      "d6c6889a546c40e289881369c04709e7",
      "6781c8d13c5f4c45bb34c65e4fdcae0f",
      "5af7455bff3341a0a4c52d09b8205f4f",
      "2f421378e9184ed3b15dd41c96a4ce37",
      "a6e58c226ada4c36af819b3e058c4dff",
      "36bf34c507224f72bd8492c152ff187e",
      "8675441d05d84340b13bf0bcd245453a",
      "fcd91bb9d261428a84a1796ab3ef18ee",
      "c0e04c54f73e4bfc919c8fe437032587",
      "1b2df3f4f2024941be942eb6d1be6835",
      "c2a1016f9f3445f2986c35a69edabe91",
      "f1663c886d4146d7960bd1ee586642b6",
      "53763c1234b04cfd9eb66f271e821ce2",
      "7efbae6e11cf45d789e40211d57ab0c8",
      "6daa61cb91cb439ab636668325c0472e",
      "fe29b5cd0e9e48d486cab0410a0562f1",
      "2bdde31e49bc464a910aa2e336940e35",
      "d79e0256762b409c83c332728a3df1c0",
      "5de34ba4c67641a2ba3948f83d31ad6a",
      "4df7aac9384749538bf894ff1b24b2ab",
      "b992849e57ad461aaaa1c5922e4a0289",
      "56feda0570e047119829330cb6969c4f"
     ]
    },
    "executionInfo": {
     "elapsed": 6218,
     "status": "ok",
     "timestamp": 1756445401733,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "HQrmHOGjfduK",
    "outputId": "1f82ca36-ed29-453a-cb0a-39bc5d603e7d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86dc60775434c688cc5d6516202c478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59f9c4c0b3da439eaa0aefde8572e050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24206ffc96e47b89fd72efae771f6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4bdb2c967894e4faebda24adebb36ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b702c2cf5bb40fba95c5767cc7095cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b5943ade704016888546cd3808a570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e009c6ef14ca4ba9b96aa5f35a74ef52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02df5c4dbaab4992a113f135da53fee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f8a9d2c1cf4e3f8511121ae6f81e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c6889a546c40e289881369c04709e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1663c886d4146d7960bd1ee586642b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === SEMANTIC SIMILARITY MODEL ===\n",
    "model_st = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cpu\")\n",
    "\n",
    "# === SEMANTIC EVALUATION FUNCTION ===\n",
    "def compute_semantic_similarity(model, tokenizer, dataset, output_file=None):\n",
    "    model.eval()\n",
    "    examples = dataset.to_list()\n",
    "    inputs = [ex[\"input\"] for ex in examples]\n",
    "    gold_outputs = [ex[\"output\"] for ex in examples]\n",
    "\n",
    "    generated_outputs = []\n",
    "    for inp in inputs:\n",
    "        inputs_tokenized = tokenizer(inp, return_tensors=\"pt\").to(model.device)\n",
    "        prompt_len = inputs_tokenized.input_ids.shape[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                **inputs_tokenized,\n",
    "                max_new_tokens=256,\n",
    "                do_sample=True,\n",
    "                temperature=0.7\n",
    "            )\n",
    "\n",
    "        generated_only_ids = output_ids[0][prompt_len:]\n",
    "        output_text = tokenizer.decode(generated_only_ids, skip_special_tokens=True)\n",
    "        generated_outputs.append(output_text)\n",
    "\n",
    "    emb_generated = model_st.encode(generated_outputs, convert_to_tensor=True)\n",
    "    emb_gold = model_st.encode(gold_outputs, convert_to_tensor=True)\n",
    "    scores = torch.nn.functional.cosine_similarity(emb_generated, emb_gold)\n",
    "    avg_score = float(scores.mean())\n",
    "\n",
    "    if output_file:\n",
    "        output_data = [{\n",
    "            \"input\": inp,\n",
    "            \"generated_output\": gen_out,\n",
    "            \"gold_output\": gold_out,\n",
    "            \"score\": float(score)\n",
    "        } for inp, gen_out, gold_out, score in zip(inputs, generated_outputs, gold_outputs, scores)]\n",
    "\n",
    "        with open(output_file, \"w\") as f:\n",
    "            json.dump(output_data, f, indent=4)\n",
    "\n",
    "    model.train()\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1756445401746,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "WcB2xsr4fv5f"
   },
   "outputs": [],
   "source": [
    "# === CALLBACK FOR EVALUATION AT EACH CHECKPOINT ===\n",
    "class SemanticSimilarityCallback(TrainerCallback):\n",
    "    def __init__(self, model, tokenizer, test_dataset, output_dir):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.test_dataset = test_dataset\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        print(f\"ðŸ”„ Step finished: {state.global_step}\")\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        print(\"\\nâœ¨ Evaluating semantic similarity at checkpoint save âœ¨\\n\")\n",
    "        if not hasattr(self, \"model\") or self.model is None:\n",
    "            print(\"Error: self.model is None.\")\n",
    "            return\n",
    "\n",
    "        #trainer.model.eval()\n",
    "        step = state.global_step\n",
    "        print(f\"creating evaluation file for checkpoint {step}\")\n",
    "        output_file = os.path.join(self.output_dir, f\"evaluation_checkpoint-{step}.json\")\n",
    "        print(f\"evaluation file: {output_file}\")\n",
    "\n",
    "        print(f\"calculating semantic similarity for checkpoint {step}\")\n",
    "        score = compute_semantic_similarity(\n",
    "            self.model,\n",
    "            self.tokenizer,\n",
    "            self.test_dataset,\n",
    "            output_file=output_file\n",
    "        )\n",
    "\n",
    "        #trainer.model.train()\n",
    "        print(f\"\\nâœ… Checkpoint {step}: Semantic Similarity = {score:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9bbc986c6bdf466cafead0be18394564",
      "6e51f1b05b4f4e019340503a0bd8911a",
      "5169fcd42b9f49ecb43f48befb157a67",
      "5478d3826be04df7ae7a28d4258e1418",
      "4e52b1d1e76c4150a6218ae31812aed9",
      "b5da73f9ebc54663b65fc2a69fcfbbf1",
      "588b66d6259c44bb9d6725b711e39e57",
      "5f945743c322468e9db2970fe001e017",
      "64e01b4591c64c19b953445e261bb14a",
      "af2bd632751c423685ef182bc5066050",
      "9d4050b8f0ae49a9b9788d6d132d2dad",
      "7f841bb62cd84005803419dad0093cc3",
      "377f41e7fad2478f8d1adfecf328c9fc",
      "3e6821765fdc4233b614aed579e7fba5",
      "a0be819680374b93a631d9ea3d065ea2",
      "75c9d05150f54b5a81ae597f1dc1f866",
      "5641830696a74edab77f422460f5b496",
      "413b50d88be641698a6dcce651784bfa",
      "fc66d4cf231348f4ab490af6c809c041",
      "37fd713e99c342da92a3849c2a04a180",
      "e237f7fbd86c4f88a642666b6c684514",
      "bf31076256204a1ab8c9b577e9c6e6aa",
      "6f589d0a33d8459888afd30fa84ded6a",
      "821d1bc4749f4f079bb91f05c57262fd",
      "ea0363a3b9714330997872d5827a64c5",
      "5f41a28a58164f59ac0588fef3e061d8",
      "92f3e1d52c85434fb376e41f858e4705",
      "16be0fe7f65f452281cc1e4b98e63657",
      "0ec68f849dae4555841d9cc6f45454f5",
      "8debf9476ac04539b7405b1318e68232",
      "d2f4ff80c0004c8eaa507f283d179c02",
      "9c902ec0d5974d218c7c209e0c57498d",
      "580424b592fe46cab7ad2aae406e7c62",
      "06eaea0512ae4f03a66faab5a25a15e5",
      "0e9ac86f67a340f3a73f303dffde4267",
      "b0667669eb8f47ce9b4afcc7fee3ca69",
      "0c54bf77ee9145c990a960769cd91a59",
      "1b398a9d37cb42bfab4e715261853a2e",
      "56ab6e732a0a480db3cd2c104d93a899",
      "48862f0ada94403dabff22545636d4dc",
      "a781b51e80154ff892024ef33632bb14",
      "84a11cb0f4974d19ab23af3b6caaa077",
      "6da95e4d590e4731a7f12529191f837a",
      "e50270cad44d4734ab599aae72f811d6",
      "a32940a6d40f400c9c33362b98e4e77d",
      "6149a593646b448ebef90f481efb8a93",
      "5f971a0a049246828b03a387fe49aaf1",
      "7092c9607d934e7e9911487c9d56de49",
      "024564d22286494b9c04e42ccec64e77",
      "140dae3afa6c462995b9f9d64c12b2fa",
      "76a68e075a01408f9b2477b78fa23960",
      "8b38262589fb4bc781e2502e28138afd",
      "8b21ce4b176b4e0981e6bb760df59e51",
      "5a53cdfb6e36439bae2f0d860f087044",
      "4d4aca6d7a614c978864be6974d555ab",
      "23390b0813d94194942d5b7270470ee4",
      "03adde0ab8924f31b90c09e49c1a2470",
      "10d4684a1c7d427793d739c5241029d7",
      "8b5a78487a864561ab749221c616b777",
      "1e658d6db524415daac9a4456947b3d0",
      "843bcf6f1d0f4f7890c603e19d591712",
      "a7567da9f0cf4111b24d9b01b6fbff8c",
      "8184307c19c74ecd8cf9d25822e24289",
      "2627bfdeedab4a40b76952b257f26bcf",
      "66d89060c75f4327930b0c5fe8dadee2",
      "1372d778c4f94b208298462d3481469a",
      "6d389a3e223940c5a8d0cc7a0445b50d",
      "111a8681ace94fa7b1df64d104cc4c72",
      "00c036396c774bc2a7259be13506e627",
      "57b0444ed88f4148841f8ede95a3ccb4",
      "4479314852354aa7a6a1e79e14732fd3",
      "40301172b4c3426eb29887bef996df9a",
      "fd57b8b8fe2249d4b6c77aab5da55c07",
      "900d9d7b55d14f7386c672ba28e3ff31",
      "3d4921c74e1b4c6086a438fcc98934ee",
      "211301eae7a14c679535daad3c679183",
      "6608d1b2c9f84202aa8f77c90efe0f5c",
      "26eeb691dd244e21815166cb9a6baba0",
      "c567ef143c27454b92dd02dcf61dd766",
      "0731ffc377224fed8407596242e9fab1",
      "cd705665a0744e4c8f59db3588e02c08",
      "2714e4c4d3424dc79940c43cfc016062",
      "a8f0c831347a4f24a3b1e940833cf7c4",
      "0d70378e07254a3a87f43e986d9ae276",
      "d9aa1d4bbb3d47aea3d0f3d27e89417b",
      "dbbfd8702ff144f9b44707c8dbc34c54",
      "4fd0cd1c19164ff78a1afa355f207247",
      "4c727d6b61df46f097513f1bb20a7a52"
     ]
    },
    "executionInfo": {
     "elapsed": 600428,
     "status": "ok",
     "timestamp": 1756446002175,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "Rk-sBS3sf08M",
    "outputId": "04030e7a-172c-44cb-cdb6-2c0f0bd26882"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-269036231.py:28: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Evaluating before training (semantic similarity)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bbc986c6bdf466cafead0be18394564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f841bb62cd84005803419dad0093cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score before training: 0.5963\n",
      "ðŸ”„ Step finished: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 09:14, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.550900</td>\n",
       "      <td>0.416283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>0.339781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.330846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Step finished: 2\n",
      "ðŸ”„ Step finished: 3\n",
      "ðŸ”„ Step finished: 4\n",
      "ðŸ”„ Step finished: 5\n",
      "ðŸ”„ Step finished: 6\n",
      "ðŸ”„ Step finished: 7\n",
      "ðŸ”„ Step finished: 8\n",
      "ðŸ”„ Step finished: 9\n",
      "ðŸ”„ Step finished: 10\n",
      "ðŸ”„ Step finished: 11\n",
      "ðŸ”„ Step finished: 12\n",
      "ðŸ”„ Step finished: 13\n",
      "ðŸ”„ Step finished: 14\n",
      "ðŸ”„ Step finished: 15\n",
      "ðŸ”„ Step finished: 16\n",
      "ðŸ”„ Step finished: 17\n",
      "ðŸ”„ Step finished: 18\n",
      "ðŸ”„ Step finished: 19\n",
      "ðŸ”„ Step finished: 20\n",
      "\n",
      "âœ¨ Evaluating semantic similarity at checkpoint save âœ¨\n",
      "\n",
      "creating evaluation file for checkpoint 20\n",
      "evaluation file: ./qwen2.5-0.5b-instruct-lora-output/evaluation_checkpoint-20.json\n",
      "calculating semantic similarity for checkpoint 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f589d0a33d8459888afd30fa84ded6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06eaea0512ae4f03a66faab5a25a15e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Checkpoint 20: Semantic Similarity = 0.9719\n",
      "\n",
      "ðŸ”„ Step finished: 21\n",
      "ðŸ”„ Step finished: 22\n",
      "ðŸ”„ Step finished: 23\n",
      "ðŸ”„ Step finished: 24\n",
      "ðŸ”„ Step finished: 25\n",
      "ðŸ”„ Step finished: 26\n",
      "ðŸ”„ Step finished: 27\n",
      "ðŸ”„ Step finished: 28\n",
      "ðŸ”„ Step finished: 29\n",
      "ðŸ”„ Step finished: 30\n",
      "ðŸ”„ Step finished: 31\n",
      "ðŸ”„ Step finished: 32\n",
      "ðŸ”„ Step finished: 33\n",
      "ðŸ”„ Step finished: 34\n",
      "ðŸ”„ Step finished: 35\n",
      "ðŸ”„ Step finished: 36\n",
      "ðŸ”„ Step finished: 37\n",
      "ðŸ”„ Step finished: 38\n",
      "ðŸ”„ Step finished: 39\n",
      "ðŸ”„ Step finished: 40\n",
      "\n",
      "âœ¨ Evaluating semantic similarity at checkpoint save âœ¨\n",
      "\n",
      "creating evaluation file for checkpoint 40\n",
      "evaluation file: ./qwen2.5-0.5b-instruct-lora-output/evaluation_checkpoint-40.json\n",
      "calculating semantic similarity for checkpoint 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32940a6d40f400c9c33362b98e4e77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23390b0813d94194942d5b7270470ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Checkpoint 40: Semantic Similarity = 0.9711\n",
      "\n",
      "ðŸ”„ Step finished: 41\n",
      "ðŸ”„ Step finished: 42\n",
      "ðŸ”„ Step finished: 43\n",
      "ðŸ”„ Step finished: 44\n",
      "ðŸ”„ Step finished: 45\n",
      "ðŸ”„ Step finished: 46\n",
      "ðŸ”„ Step finished: 47\n",
      "ðŸ”„ Step finished: 48\n",
      "ðŸ”„ Step finished: 49\n",
      "ðŸ”„ Step finished: 50\n",
      "ðŸ”„ Step finished: 51\n",
      "ðŸ”„ Step finished: 52\n",
      "ðŸ”„ Step finished: 53\n",
      "ðŸ”„ Step finished: 54\n",
      "ðŸ”„ Step finished: 55\n",
      "ðŸ”„ Step finished: 56\n",
      "ðŸ”„ Step finished: 57\n",
      "ðŸ”„ Step finished: 58\n",
      "ðŸ”„ Step finished: 59\n",
      "ðŸ”„ Step finished: 60\n",
      "\n",
      "âœ¨ Evaluating semantic similarity at checkpoint save âœ¨\n",
      "\n",
      "creating evaluation file for checkpoint 60\n",
      "evaluation file: ./qwen2.5-0.5b-instruct-lora-output/evaluation_checkpoint-60.json\n",
      "calculating semantic similarity for checkpoint 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d389a3e223940c5a8d0cc7a0445b50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26eeb691dd244e21815166cb9a6baba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Checkpoint 60: Semantic Similarity = 0.9798\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=60, training_loss=0.5045756061871847, metrics={'train_runtime': 563.1789, 'train_samples_per_second': 0.852, 'train_steps_per_second': 0.107, 'total_flos': 990264125030400.0, 'train_loss': 0.5045756061871847, 'epoch': 10.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === TRAINING ===\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4,\n",
    "    bf16=True,\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_steps=20,\n",
    "    save_total_limit=10,\n",
    "    report_to=\"none\",\n",
    "    max_steps=60,\n",
    "    disable_tqdm=False\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, force=True)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[SemanticSimilarityCallback(model, tokenizer, dataset[\"test\"], OUTPUT_DIR)],\n",
    ")\n",
    "\n",
    "# Add semantic evaluation callback\n",
    "# semantic_callback = SemanticSimilarityCallback(tokenizer, dataset[\"test\"], OUTPUT_DIR)\n",
    "# trainer.add_callback(semantic_callback)\n",
    "\n",
    "# Initial evaluation before training\n",
    "print(\"\\nðŸ” Evaluating before training (semantic similarity)...\")\n",
    "score_before = compute_semantic_similarity(model, tokenizer, dataset[\"test\"], output_file=os.path.join(OUTPUT_DIR, \"evaluation_avant.json\"))\n",
    "print(f\"Average score before training: {score_before:.4f}\")\n",
    "\n",
    "# Training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1756446002390,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "KzMG0CeVoYtu",
    "outputId": "e4813d6a-64f1-4b88-ebed-7966cb060240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/DLAA_2025/qwen2.5-0.5b-instruct-lora-output\n",
      "/content/drive/MyDrive/DLAA_2025/qwen2.5-0.5b-instruct-lora-output\n",
      "checkpoint-20  evaluation_avant.json\t      evaluation_checkpoint-60.json\n",
      "checkpoint-40  evaluation_checkpoint-20.json  plotdiag\n",
      "checkpoint-60  evaluation_checkpoint-40.json\n"
     ]
    }
   ],
   "source": [
    "%cd qwen2.5-0.5b-instruct-lora-output/\n",
    "!pwd\n",
    "!ls"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN6TMJuPF+H1eRfcHpG3xQ9",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
