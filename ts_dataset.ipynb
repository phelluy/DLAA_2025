{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNeFh060hIG0+sgXC/knrs3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd \"/content/drive/My Drive/DLAA_2025\"\n","%ls\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_eCPNjmDaM1x","executionInfo":{"status":"ok","timestamp":1756447230429,"user_tz":-120,"elapsed":29169,"user":{"displayName":"Philippe Helluy","userId":"07790988964707423334"}},"outputId":"865870d4-9812-4eec-cafa-d45cce6bea30"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/My Drive/DLAA_2025\n","check_training.ipynb  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/                        time_series.ipynb\n","dataset.jsonl         \u001b[01;34mqwen2.5-0.5b-instruct-lora-output\u001b[0m/  ts_dataset.ipynb\n","/content/drive/My Drive/DLAA_2025\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"WM5Pnv3JZ-88","executionInfo":{"status":"ok","timestamp":1756447159302,"user_tz":-120,"elapsed":1621,"user":{"displayName":"Philippe Helluy","userId":"07790988964707423334"}}},"outputs":[],"source":["import base64\n","import requests\n","import os\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.signal import savgol_filter\n","\n","prompt_ts = r\"\"\"\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","\"\"\""]},{"cell_type":"code","source":["# check that a json object can be extracted from a string and that\n","# the json object has the keys \"trend\", \"noise\", and \"extrema\"\n","# additional keys are allowed\n","def check_json_format(json_string):\n","    try:\n","        # Attempt to strip potential markdown code block fences ```json ... ``` or ``` ... ```\n","        if json_string.strip().startswith(\"```json\"):\n","            json_string = json_string.strip()[7:-3].strip()\n","        elif json_string.strip().startswith(\"```\"):\n","             json_string = json_string.strip()[3:-3].strip()\n","\n","        print(\"json_string=\", json_string)\n","        json_object = json.loads(json_string)\n","        if \"trend\" in json_object and \"noise\" in json_object and \"extrema\" in json_object:\n","            return True\n","        else:\n","            print(\"Warning: JSON object missing required keys.\")\n","            return False\n","    except json.JSONDecodeError as e:\n","        print(f\"Warning: Failed to decode JSON: {e}\")\n","        return False\n","    except Exception as e: # Catch other potential errors during processing\n","        print(f\"Warning: An error occurred during JSON check: {e}\")\n","        return False"],"metadata":{"id":"ft4MBUPiavCz","executionInfo":{"status":"ok","timestamp":1756447309860,"user_tz":-120,"elapsed":45,"user":{"displayName":"Philippe Helluy","userId":"07790988964707423334"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# a small class for generating Orstein Uhlenbeck process together with an automatic\n","# human readible description of the process\n","class OUProcess:\n","    def __init__(self):\n","        #self.seed = 0\n","        # give the seed to numpy\n","        self.theta=0.7      # Speed of mean reversion: higher values pull X(t) faster towards the mean\n","        #self.slope = 0.0    # Slope of the mean curve\n","        self.mu=0.0         # Long-term mean: the value to which the process tends to revert\n","        self.sigma=0.      # Volatility: the intensity of the random fluctuations (Brownian motion component)\n","        self.x0=0.0         # Initial value of the process\n","        self.T=1.0          # Total time\n","\n","    def generate(self, imagename=\"ou_process.png\", filename=\"ou_process.dat\"):\n","        #print(self.dt)\n","        N = 128\n","        self.dt = self.T/N\n","        #print(self.dt)\n","        # N = int(self.T / self.dt) # This line is redundant as N is already defined\n","        t = np.linspace(0, self.T, N)      # Time grid\n","        ti = np.arange(0, N)  # Time grid for plotting\n","        X = np.zeros(N)               # Array to store the process values\n","\n","        # list of three sentence fact checked sentences\n","        sentences = []\n","        description = dict()\n","        # Apply random variations to parameters for diversity\n","        # Ensure parameters stay within reasonable bounds if necessary\n","        theta = max(0.1, self.theta + np.random.uniform(-0.5, 0.5)) # Keep theta positive\n","        mu = self.mu + np.random.uniform(-1,1)*2\n","        mu = 0.5\n","        sigma = self.sigma + np.random.uniform(0., 0.4)\n","        #slope = self.slope+ np.random.uniform(-1,1)*0.25\n","        #sigma = 0 # Keep this commented unless you specifically want no noise\n","        x0 = self.x0 + np.random.uniform(-1,1)*2\n","        #x0 = 0.5\n","        X[0] = x0                     # Initial value\n","\n","\n","        # Use a fixed seed for reproducibility *within a single generation* if needed\n","        # np.random.seed(self.seed) # Uncomment if you want deterministic generation based on seed\n","\n","        for i in range(1, N):\n","            dW = np.random.normal(0, np.sqrt(self.dt))  # Brownian increment\n","            X[i] = X[i-1] + theta * (mu - X[i-1]) * self.dt + sigma * dW\n","            #X[i] = X[i-1] + slope * self.dt + sigma * dW\n","            # remet X dans l'intervalle [0,1]\n","            #X[i] = np.clip(X[i], 0, 1)\n","\n","        # get the max of the sequence\n","        max_value = np.max(X)\n","        # get the min of the sequence\n","        min_value = np.min(X)\n","        # scale the sequence so that all the values are between 0 and 99.9999\n","        X = (X - min_value) / (max_value - min_value) * 99.9999\n","        # round the values to 0 decimal places and convert to integer\n","        X = np.floor(X).astype(int)\n","\n","\n","        # compute the average of the solution on the 20 first points\n","        average1 = np.mean(X[:20])\n","        # compute the average of the solution on the 20 last points\n","        average2 = np.mean(X[-20:])\n","\n","        # if slope > sigma*0.1:\n","        #     description['trend'] = \"the time series shows an overall increasing trend.\"\n","        # elif slope < -sigma*0.1:\n","        #     description['trend'] = \"the time series shows an overall decreasing trend.\"\n","        # else:\n","        #     description['trend'] = \"the time series shows no clear trend.\"\n","\n","\n","        if average1 < average2 -3:\n","            description['trend'] = \"the time series shows an overall increasing trend.\"\n","        elif average1 > average2 +3:\n","            description['trend'] = \"the time series shows an overall decreasing trend.\"\n","        else:\n","            description['trend'] = \"the time series shows no uniformly increasing or decreasing trend.\"\n","\n","\n","        if sigma < 0.1:\n","            description['noise']=\"the time series presents many small fluctuations.\"\n","        elif sigma > 0.3:\n","            description['noise']=\"the time series presents many large fluctuations.\"\n","        else:\n","            description['noise']=\"the time series presents many moderate fluctuations.\"\n","\n","\n","        # recherche de la localisation en t du maximum et du minimum\n","        pos_max = np.argmax(X)\n","        print('pos_max', pos_max)\n","        if pos_max < 32:\n","            pos_desc = \"The maximum is reached around the beginning part of the time series\"\n","        elif pos_max > 96:\n","            pos_desc = \"The maximum is reached towards the end of the time series\"\n","        else:\n","            pos_desc = \"The maximum is reached around the middle of the time series\"\n","\n","        pos_min = np.argmin(X)\n","        print('pos_min', pos_min)\n","        if pos_min < 32:\n","            pos_desc += \" and the minimum is reached around the beginning part of the time series.\"\n","        elif pos_min > 96:\n","            pos_desc += \" and the minimum is reached towards the end of the time series.\"\n","        else:\n","            pos_desc += \" and the minimum is reached around the middle of the time series.\"\n","\n","        description['extrema'] = pos_desc\n","        description['parameters'] = \"sigma=\"+str(sigma) + \" mu=\" + str(mu) + \" x0=\" + str(x0) + \" theta=\" + str(theta)\n","\n","        # convert to a json string\n","        description = json.dumps(description)\n","\n","        # Save the process to a file\n","        np.savetxt(filename, X)\n","\n","        plt.figure(figsize=(10, 5))\n","        # fix the y scale to between 0 and 100\n","        plt.ylim(0, 100)\n","        # fix the aspect ration to 1\n","        plt.gca().set_aspect('equal', adjustable='box')\n","        # plot the time series with spline interpolation\n","\n","        #X = savgol_filter(X, window_length=1, polyorder=1)\n","\n","        plt.plot(ti, X )\n","        plt.title('Time Series')\n","        plt.xlabel('Time')\n","        plt.ylabel('X(t)')\n","        plt.grid(True)\n","        # now save the picture to a png file\n","        plt.savefig(imagename)\n","        plt.close() # Close the plot to free memory\n","        return X, description\n"],"metadata":{"id":"X0I-4A1xa8da","executionInfo":{"status":"ok","timestamp":1756447365045,"user_tz":-120,"elapsed":32,"user":{"displayName":"Philippe Helluy","userId":"07790988964707423334"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"rhgy4jZcb5ZP"}},{"cell_type":"code","source":["import os\n","\n","# Set the environment variable for TEXTSYNTH_API_KEY\n","os.environ['TEXTSYNTH_API_KEY'] = '94820bdeeba5457cbc28f3c83a26df61'\n","\n","# You can optionally print it to verify\n","print(f\"TEXTSYNTH_API_KEY set: {os.environ.get('TEXTSYNTH_API_KEY') is not None}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8sF1up9sbvik","executionInfo":{"status":"ok","timestamp":1756448641433,"user_tz":-120,"elapsed":47,"user":{"displayName":"Philippe Helluy","userId":"07790988964707423334"}},"outputId":"19bb7528-1665-47ef-d439-93e3c4b134a1"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["TEXTSYNTH_API_KEY set: True\n"]}]},{"cell_type":"code","source":["import base64\n","import requests\n","import os\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.signal import savgol_filter\n","import re # Added re for removing the think block\n","\n","# a simple class for asking questions to a LLM about a given picture\n","# the picture is encoded in base64 and sent to the LLM\n","class Mistral:\n","    def __init__(self, dryrun = False, image = False):\n","        self.dryrun = dryrun\n","        self.image = image\n","        if image:\n","            self.api_key = os.environ.get(\"MISTRAL_API_KEY\")\n","            if not self.api_key and not dryrun:\n","                raise ValueError(\"MISTRAL_API_KEY environment variable not set.\")\n","            self.api_url = \"https://api.mistral.ai/v1/chat/completions\"\n","            #self.model = \"mistral-large-latest\" # Using the recommended model for function calling / JSON mode\n","            self.model = \"pixtral-large-latest\"\n","            #self.model = \"pixtral-12b-2409\"\n","            #self.model = \"pixtral-large-latest\" # Use pixtral if image input is definitely needed later\n","            print(\"Mistral initialized\")\n","        else:\n","            # Set the environment variable here in Python\n","            os.environ['TEXTSYNTH_API_KEY'] = '94820bdeeba5457cbc28f3c83a26df61' # Assuming this is the correct key\n","            self.api_key = os.environ.get(\"TEXTSYNTH_API_KEY\")\n","\n","            if not self.api_key and not dryrun:\n","                raise ValueError(\"TEXTSYNTH_API_KEY environment variable not set.\")\n","            self.api_url = \"https://palgania.ovh:8106/v1/chat/completions\"\n","            # self.api_url = \"http://0.0.0.0:8080/v1/chat/completions\" # Commented out local host\n","            self.model = \"qwen3-30b-a3b\" # Using the recommended model for function calling / JSON mode\n","            print(\"Palgania initialized\")\n","\n","        #print(f\"Mistral API key: {'Set' if self.api_key else 'Not Set'}\")\n","        print(f\"LLM API URL: {self.api_url}\")\n","        print(f\"LLM model: {self.model}\")\n","        print(f\"Dry run: {self.dryrun}\")\n","\n","    def encode_image(self, image_path):\n","        \"\"\"Encode the image to base64.\"\"\"\n","        try:\n","            with open(image_path, \"rb\") as image_file:\n","                return base64.b64encode(image_file.read()).decode('utf-8')\n","        except FileNotFoundError:\n","            print(f\"Error: The file {image_path} was not found.\")\n","            return None\n","        except Exception as e:\n","            print(f\"Error encoding image {image_path}: {e}\")\n","            return None\n","\n","    def ask_noimage(self, question):\n","        \"\"\"Ask a question using the model without an image.\"\"\"\n","        headers = {\n","            \"Content-Type\": \"application/json\",\n","            \"Accept\": \"application/json\",\n","            \"Authorization\": f\"Bearer {self.api_key}\"\n","        }\n","        payload = {\n","            \"model\": self.model,\n","            \"messages\": [\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": [\n","                        {\"type\": \"text\", \"text\": question}\n","                    ]\n","                }\n","            ],\n","            \"response_format\": {\"type\": \"json_object\"},\n","            \"temperature\": 0.7,\n","            \"max_tokens\": 512,\n","            \"top_p\": 1.0,\n","            \"safe_prompt\": False\n","        }\n","\n","        if self.dryrun:\n","            print(f\"Dry run: Simulating API call for question '{question}'\")\n","            # Generate a fake but valid answer\n","            content = {\n","                \"response\": \"This is a simulated response to your question.\"\n","            }\n","            # Simulate the structure of the actual API response\n","            return {\"choices\": [{\"message\": {\"content\": json.dumps(content)}}]}\n","        else:\n","            try:\n","                print(f\"Sending request to API for question '{question}'...\")\n","                # Added verify=False to disable SSL verification\n","                response = requests.post(self.api_url, headers=headers, json=payload, timeout=60, verify=False)\n","                response.raise_for_status()\n","                print(\"Request successful.\")\n","                return response.json()\n","            except requests.exceptions.RequestException as e:\n","                print(f\"Error calling API: {e}\")\n","                # Log more details if available in the response\n","                if hasattr(e, 'response') and e.response is not None:\n","                    print(f\"Response status code: {e.response.status_code}\")\n","                    try:\n","                        print(f\"Response text: {e.response.text}\")\n","                    except Exception as json_err:\n","                        print(f\"Could not decode error response JSON: {json_err}\")\n","                return None\n","            except Exception as e:\n","                print(f\"An unexpected error occurred during API call: {e}\")\n","                return None\n","\n","\n","    def ask(self, image_path, question):\n","        \"\"\"Ask a question about the image using LLM API\"\"\"\n","        # Ensure model is Pixtral for image input\n","        # if not self.model.startswith(\"pixtral\"):\n","        #     print(f\"Warning: Model {self.model} may not support image input. Trying anyway.\")\n","            # Or force switch: self.model = \"pixtral-large-latest\"\n","\n","        base64_image = self.encode_image(image_path)\n","        if not base64_image:\n","            print(f\"Skipping request due to image encoding error for {image_path}\")\n","            return None\n","\n","        headers = {\n","            \"Content-Type\": \"application/json\",\n","            \"Accept\": \"application/json\", # Added for clarity\n","            \"Authorization\": f\"Bearer {self.api_key}\"\n","        }\n","        payload = {\n","            \"model\": self.model,\n","             \"messages\": [\n","                {\n","                    \"role\": \"user\",\n","                    \"content\": [\n","                        {\"type\": \"text\", \"text\": question},\n","                        {\n","                            \"type\": \"image_url\",\n","                            \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"} # Use correct MIME type\n","                        }\n","                    ]\n","                }\n","            ],\n","            \"response_format\": {\"type\": \"json_object\"},\n","            \"temperature\": 0.7,\n","            \"max_tokens\": 512, # Reduced max_tokens as the expected output is small\n","            \"top_p\": 1.0, # Adjusted top_p as per recommendations for JSON mode\n","            \"safe_prompt\": False\n","        }\n","\n","        if self.dryrun:\n","            print(f\"Dry run: Simulating API call for image {os.path.basename(image_path)}\")\n","            # Generate a fake but valid answer\n","            content = {\n","                \"trend\": \"The time series shows a fluctuating trend.\",\n","                \"noise\": \"There appears to be moderate noise influencing the series.\",\n","                \"extrema\": \"Local maxima and minima are visible throughout the series, with global extrema near the start and middle.\"\n","            }\n","            # Simulate the structure of the actual API response\n","            return {\"choices\": [{\"message\": {\"content\": json.dumps(content)}}]}\n","        else:\n","            try:\n","                print(f\"Sending request to LLM API for image {os.path.basename(image_path)}...\")\n","                # Added verify=False to disable SSL verification\n","                response = requests.post(self.api_url, headers=headers, json=payload, timeout=60, verify=False)\n","                response.raise_for_status() # Raise HTTPError for bad responses (4xx or 5xx)\n","                print(\"Request successful.\")\n","                return response.json()\n","            except requests.exceptions.RequestException as e:\n","                print(f\"Error calling LLM API: {e}\")\n","                # Log more details if available in the response\n","                if hasattr(e, 'response') and e.response is not None:\n","                    print(f\"Response status code: {e.response.status_code}\")\n","                    try:\n","                        print(f\"Response text: {e.response.text}\")\n","                    except Exception as json_err:\n","                        print(f\"Could not decode error response JSON: {json_err}\")\n","                return None\n","            except Exception as e: # Catch any other unexpected errors\n","                print(f\"An unexpected error occurred during API call: {e}\")\n","                return None\n","\n","    def load_dataset(self):\n","        directory = \"dataset\"\n","        json_file_path = os.path.join(directory, \"data.jsonl\")  # Change to data.jsonl\n","\n","        # Ensure the directory exists\n","        os.makedirs(directory, exist_ok=True)\n","\n","        # --- CHANGE 1: Load existing data ---\n","        self.data_json = []\n","        start_index = 0\n","        if os.path.exists(json_file_path):\n","            try:\n","                with open(json_file_path, \"r\") as f:\n","                    self.data_json = []\n","                    for line in f:\n","                        try:\n","                            entry = json.loads(line)\n","                            self.data_json.append(entry)\n","                        except json.JSONDecodeError as e:\n","                            print(f\"Warning: Could not decode JSON from line: {line}. Error: {e}\")\n","                    # Ensure data_json is a list\n","                    if not isinstance(self.data_json, list):\n","                        print(f\"Warning: {json_file_path} does not contain valid JSON lines. Starting fresh.\")\n","                        self.data_json = []\n","                    else:\n","                        # --- CHANGE 2: Calculate starting index ---\n","                        start_index = len(self.data_json)\n","                        print(f\"Loaded {start_index} existing entries from {json_file_path}.\")\n","            except json.JSONDecodeError:\n","                print(f\"Warning: Could not decode JSON from {json_file_path}. Starting fresh.\")\n","                self.data_json = []\n","            except Exception as e:\n","                print(f\"Warning: Error reading {json_file_path}: {e}. Starting fresh.\")\n","                self.data_json = []\n","        else:\n","            print(f\"{json_file_path} not found. Creating a new dataset.\")\n","            # just create an empty file\n","            with open(json_file_path, 'w') as file:\n","                pass\n","\n","    def save_dataset(self):\n","        directory = \"dataset\"\n","        if not os.path.exists(directory):\n","            os.makedirs(directory)\n","        json_file_path = os.path.join(directory, 'data2.jsonl')\n","        with open(json_file_path, 'w') as file:\n","            for entry in self.data_json:\n","                file.write(json.dumps(entry) + '\\n')\n","\n","    # recompute the truth\n","    def redo_truth(self):\n","        self.load_dataset()\n","        np.random\n","        for i in range(len(self.data_json)):\n","            X = np.array(self.data_json[i][\"series\"])\n","            x = np.arange(len(X))\n","            coeffs = np.polyfit(x, X, deg=3)\n","            P = np.poly1d(coeffs)\n","            X_fit = P(x)\n","            # compute the l2 norm of the difference\n","            l2_norm = np.linalg.norm(X - X_fit)/np.sqrt(len(X))\n","            # plt.plot(x,X)\n","            # plt.plot(x,X_fit)\n","            # plt.show()\n","            Pp = P.deriv()\n","            Xp_fit = Pp(x)\n","            delta = Xp_fit[-1] - Xp_fit[0]\n","            # divmin = np.min(Xp_fit)\n","            # divmax = np.max(Xp_fit)\n","            # if divmin > 0:\n","            #     sentence =  \"the time series presents an overall increasing trend\"\n","            # elif divmax < 0:\n","            #     sentence = \"the time series presents an overall decreasing trend\"\n","            # else:\n","            #     sentence = \"the time series presents no uniformly increasing or decreasing trend\"\n","            # if delta > 5:\n","            #     sentence =  \"the time series presents an overall increasing trend\"\n","            # elif delta < -5:\n","            #     sentence = \"the time series presents an overall decreasing trend\"\n","            # else:\n","            #     sentence = \"the time series presents no uniformly increasing or decreasing trend\"\n","            # compute the average of the solution on the 20 first points\n","            average1 = np.mean(X[:20])\n","            # compute the average of the solution on the 20 last points\n","            average2 = np.mean(X[-20:])\n","            if average1 < average2 -3:\n","                sentence = \"the time series shows an overall increasing trend.\"\n","            elif average1 > average2 +3:\n","                sentence = \"the time series shows an overall decreasing trend.\"\n","            else:\n","                sentence = \"the time series shows no uniformly increasing or decreasing trend.\"\n","            self.data_json[i][\"truth_description\"][\"trend\"] = sentence\n","\n","            print(f\"{i} L2 norm of the difference: {l2_norm}\")\n","            #sentence_noise = self.data_json[i][\"description\"][\"noise\"]\n","            if l2_norm < 2:\n","                sentence_noise = \"the noise intensity is low\"\n","            elif l2_norm > 12:\n","                sentence_noise = \"the noise intensity is high\"\n","            else:\n","                sentence_noise = \"the noise intensity is medium\"\n","            print(sentence_noise)\n","            self.data_json[i][\"truth_description\"][\"noise\"] = sentence_noise\n","        self.save_dataset()\n","\n","\n","\n","\n","    # generate a dataset of time series, images and description\n","    # the series, images and description are stored in the dataset directory\n","    # in the same time a json object data_json is created: it is a list of dictionnaries\n","    # each dictionnary has four entries: \"question\", \"series\", \"image\" and \"description\"\n","    # the series is a list of floats, the image is a string containing the path to the image\n","    # and the description is a string\n","    def dataset(self, n):\n","        self.load_dataset()  # Load existing dataset if any\n","        start_index = len(self.data_json)\n","        directory = \"dataset\"\n","        # --- Generation Loop ---\n","        generated_count = 0\n","        max_attempts_per_item = 3  # Add a limit to retry attempts for JSON validation\n","\n","        for i in range(n):\n","            # --- CHANGE 3: Use correct index for new entries and filenames ---\n","            current_index = start_index + i\n","\n","            print(f\"Generating time series {i}/{n-1} (Overall index: {current_index})\")\n","\n","            # Define file paths using the unique current_index\n","            base_filename = f\"ou_process_{current_index}\"\n","            image_path = os.path.join(directory, f\"{base_filename}.png\")\n","            dat_path = os.path.join(directory, f\"{base_filename}.dat\")\n","            txt_path = os.path.join(directory, f\"{base_filename}.txt\")  # For saving raw description\n","\n","            ou = OUProcess()\n","            ts, truth = ou.generate(image_path, dat_path)\n","\n","            # Parse the truth description\n","            truth_dict = json.loads(truth)\n","\n","            attempts = 0\n","            valid_json_response = False\n","            while attempts < max_attempts_per_item and not valid_json_response:\n","                attempts += 1\n","                print(f\"  Attempting LLM description (Attempt {attempts}/{max_attempts_per_item})\")\n","                if self.image:\n","                    response = self.ask(image_path, prompt_ts)\n","                else:\n","                    response = self.ask_noimage(prompt_ts)\n","\n","                if response is None or \"choices\" not in response or not response[\"choices\"]:\n","                    print(\"  Error: Failed to get response from LLM or response is empty.\")\n","                    continue  # Retry if API failed\n","\n","                raw_json_string = response[\"choices\"][0][\"message\"][\"content\"]\n","                print(f\"  Raw LLM response: {raw_json_string}\")\n","                # remove the think block\n","                raw_json_string = re.sub(r'<think>.*?</think>', '', raw_json_string, flags=re.DOTALL)\n","                raw_json_string = raw_json_string.strip()\n","\n","\n","                # Save the raw response text regardless of validity for debugging\n","                try:\n","                    with open(txt_path, \"w\") as f:\n","                        f.write(raw_json_string)\n","                except IOError as e:\n","                    print(f\"  Warning: Could not write raw description to {txt_path}: {e}\")\n","\n","                # Check if the response is valid JSON and has the required keys\n","                if check_json_format(raw_json_string):\n","                    try:\n","                        # Re-parse the cleaned string if check_json_format modified it\n","                        cleaned_json_string = raw_json_string\n","                        if cleaned_json_string.strip().startswith(\"```json\"):\n","                            cleaned_json_string = cleaned_json_string.strip()[7:-3].strip()\n","                        elif cleaned_json_string.strip().startswith(\"```\"):\n","                            cleaned_json_string = cleaned_json_string.strip()[3:-3].strip()\n","\n","                        description_json = json.loads(cleaned_json_string)\n","                        ts_list = ts.tolist()\n","\n","                        self.data_json.append({\n","                            \"index\": current_index,\n","                            \"question\": prompt_ts,\n","                            \"series\": ts_list,\n","                            \"image\": image_path,\n","                            \"description\": description_json,\n","                            \"truth_description\": truth_dict\n","                        })\n","                        valid_json_response = True\n","                        generated_count += 1\n","                        print(f\"  Successfully added entry with index {current_index}.\")\n","                        break  # Exit the retry loop on success\n","                    except json.JSONDecodeError as e:\n","                        print(f\"  Error: Could not re-parse validated JSON string: {e}. Raw string was: {raw_json_string}\")\n","                    except Exception as e:\n","                        print(f\"  An unexpected error occurred while processing valid response: {e}\")\n","                else:\n","                    print(f\"  Warning: Invalid JSON format received on attempt {attempts}. Raw response was: {raw_json_string}\")\n","                    if attempts >= max_attempts_per_item:\n","                        print(f\"  Error: Max attempts reached for index {current_index}. Skipping this entry.\")\n","\n","        # --- CHANGE 4: Save the combined data as JSON Lines ---\n","        directory = \"dataset\"\n","        json_file_path = os.path.join(directory, \"data.jsonl\")\n","        try:\n","            with open(json_file_path, \"w\") as f:\n","                for entry in self.data_json:\n","                    json.dump(entry, f)\n","                    f.write('\\n')\n","            print(f\"\\nSuccessfully generated {generated_count} new entries.\")\n","            print(f\"Total entries in {json_file_path}: {len(self.data_json)}\")\n","        except IOError as e:\n","            print(f\"\\nError: Could not write updated dataset to {json_file_path}: {e}\")\n","        except TypeError as e:\n","            print(f\"\\nError: Could not serialize data to JSON: {e}. Check data types.\")\n","\n","    def curate_dataset(self):\n","        \"\"\"Curate the dataset by generating new entries and saving them as JSON Lines.\"\"\"\n","        self.load_dataset()\n","        index_to_remove = []\n","\n","        errors = [0,0,0]\n","\n","        # for each entry compute NLI score\n","        for i, entry in enumerate(self.data_json):\n","            print(f\"\\nProcessing entry {i}/{len(self.data_json)-1}\")\n","            description = entry[\"description\"]\n","            # extract the trend\n","            trend = description[\"trend\"]\n","            # extract the noise\n","            noise = description[\"noise\"]\n","            # extract the extrema\n","            extrema = description[\"extrema\"]\n","            truth_description = entry[\"truth_description\"]\n","            # extract the trend\n","            truth_trend = truth_description[\"trend\"]\n","            # extract the noise\n","            truth_noise = truth_description[\"noise\"]\n","            # extract the extrema\n","            truth_extrema = truth_description[\"extrema\"]\n","            # compute the NLI score for the trend\n","            score_trend = detect_contradiction_nli(trend, truth_trend)\n","            print(truth_description[\"parameters\"])\n","            print(\"trend\", trend)\n","            print(\"truth_trend\", truth_trend)\n","            print(\"score_trend\", score_trend)\n","            score_noise = detect_contradiction_nli(noise, truth_noise)\n","            print(\"noise\", noise)\n","            print(\"truth_noise\", truth_noise)\n","            print(\"score_noise\", score_noise)\n","            score_extrema = detect_contradiction_nli(extrema, truth_extrema)\n","            print(\"extrema\", extrema)\n","            print(\"truth_extrema\", truth_extrema)\n","            print(\"score_extrema\", score_extrema)\n","            # remove the entry from the dictionnary if the first tuple value\n","            # of one of the scores is 'no'\n","            if score_trend[0] == 'no' or score_noise[0] == 'no' or score_extrema[0] == 'no':\n","                index_to_remove.append(i)\n","                if score_trend[0] == 'no':\n","                    errors[0] += 1\n","                if score_noise[0] == 'no':\n","                    errors[1] += 1\n","                if score_extrema[0] == 'no':\n","                    errors[2] += 1\n","                    self.data_json[i][\"description\"][\"extrema\"]= self.data_json[i][\"truth_description\"][\"extrema\"]\n","\n","        print(\"errors\", errors, \"/\", len(self.data_json))\n","\n","        print(\"index_to_check\", index_to_remove)\n","        self.save_dataset()"],"metadata":{"id":"hAI2WT7LbeIs","executionInfo":{"status":"ok","timestamp":1756449574919,"user_tz":-120,"elapsed":75,"user":{"displayName":"Philippe Helluy","userId":"07790988964707423334"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["    chat = Mistral(dryrun = False, image = False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSgqhP_odcz_","executionInfo":{"status":"ok","timestamp":1756449586035,"user_tz":-120,"elapsed":16,"user":{"displayName":"Philippe Helluy","userId":"07790988964707423334"}},"outputId":"71816389-d708-426e-83ec-87520c968464"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Palgania initialized\n","LLM API URL: https://palgania.ovh:8106/v1/chat/completions\n","LLM model: qwen3-30b-a3b\n","Dry run: False\n"]}]},{"cell_type":"code","source":["    print(\"\\n--- Running dataset generation (first call) ---\")\n","    for itt in range(1):\n","      chat.dataset(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BOC5pvIZd4D9","executionInfo":{"status":"ok","timestamp":1756449601472,"user_tz":-120,"elapsed":12873,"user":{"displayName":"Philippe Helluy","userId":"07790988964707423334"}},"outputId":"232c3405-265e-4949-90d7-ec2ebc689431"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Running dataset generation (first call) ---\n","Loaded 0 existing entries from dataset/data.jsonl.\n","Generating time series 0/9 (Overall index: 0)\n","pos_max 0\n","pos_min 126\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: {\"trend\": \"The time series shows an increasing trend over the period.\", \"noise\": \"The noise intensity is medium, with some fluctuations around the trend.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is at the beginning.\"}\n","\n","json_string= {\"trend\": \"The time series shows an increasing trend over the period.\", \"noise\": \"The noise intensity is medium, with some fluctuations around the trend.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is at the beginning.\"}\n","  Successfully added entry with index 0.\n","Generating time series 1/9 (Overall index: 1)\n","pos_max 121\n","pos_min 1\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","\n","json_string= {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","  Successfully added entry with index 1.\n","Generating time series 2/9 (Overall index: 2)\n","pos_max 69\n","pos_min 2\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: {\n","  \"trend\": \"The time series shows an increasing trend over the period.\",\n","  \"noise\": \"The noise intensity is medium, with some fluctuations around the trend.\",\n","  \"extrema\": \"The global maximum is located in the middle of the time series, while the global minimum is at the beginning.\"\n","}\n","  \t\t\t   \t\t\t\t\t\n","json_string= {\n","  \"trend\": \"The time series shows an increasing trend over the period.\",\n","  \"noise\": \"The noise intensity is medium, with some fluctuations around the trend.\",\n","  \"extrema\": \"The global maximum is located in the middle of the time series, while the global minimum is at the beginning.\"\n","}\n","  Successfully added entry with index 2.\n","Generating time series 3/9 (Overall index: 3)\n","pos_max 123\n","pos_min 0\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","\n","json_string= {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","  Successfully added entry with index 3.\n","Generating time series 4/9 (Overall index: 4)\n","pos_max 63\n","pos_min 0\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: {\"trend\": \"The time series shows an increasing trend over the period.\", \"noise\": \"The noise intensity is medium, with some fluctuations around the trend.\", \"extrema\": \"The global maximum is located at the end, while the global minimum is at the beginning.\"}\n","\n","json_string= {\"trend\": \"The time series shows an increasing trend over the period.\", \"noise\": \"The noise intensity is medium, with some fluctuations around the trend.\", \"extrema\": \"The global maximum is located at the end, while the global minimum is at the beginning.\"}\n","  Successfully added entry with index 4.\n","Generating time series 5/9 (Overall index: 5)\n","pos_max 114\n","pos_min 4\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","\n","json_string= {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","  Successfully added entry with index 5.\n","Generating time series 6/9 (Overall index: 6)\n","pos_max 0\n","pos_min 121\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","\n","json_string= {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","  Successfully added entry with index 6.\n","Generating time series 7/9 (Overall index: 7)\n","pos_max 103\n","pos_min 19\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","\n","json_string= {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end, and the global minimum is located at the beginning.\"}\n","  Successfully added entry with index 7.\n","Generating time series 8/9 (Overall index: 8)\n","pos_max 0\n","pos_min 127\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end and the global minimum is located at the beginning.\"}\n","\n","json_string= {\"trend\": \"The time series shows an increasing trend.\", \"noise\": \"The noise intensity is medium.\", \"extrema\": \"The global maximum is located at the end and the global minimum is located at the beginning.\"}\n","  Successfully added entry with index 8.\n","Generating time series 9/9 (Overall index: 9)\n","pos_max 119\n","pos_min 0\n","  Attempting LLM description (Attempt 1/3)\n","Sending request to API for question '\n","/think Describe the time series in three sentences. First sentence: describe trend (increasing/decreasing/flat). Second sentence: noise intensity (low/medium/high). Third sentence: approximate localisation of global maximum (beginning/middle/end) and global minimum (beginning/middle/end).\n","Put the description in a JSON format with the following pattern\n","```json\n","{ \"trend\": <sentence1>,\n","  \"noise\": <sentence2>,\n","  \"extrema\": <sentence3> }\n","```\n","'...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'palgania.ovh'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Request successful.\n","  Raw LLM response: { \"trend\": \"The time series shows an increasing trend over the period.\", \"noise\": \"The noise intensity is medium, with some fluctuations around the trend.\", \"extrema\": \"The global maximum is located at the end, while the global minimum is at the beginning.\" }\n","\n","json_string= { \"trend\": \"The time series shows an increasing trend over the period.\", \"noise\": \"The noise intensity is medium, with some fluctuations around the trend.\", \"extrema\": \"The global maximum is located at the end, while the global minimum is at the beginning.\" }\n","  Successfully added entry with index 9.\n","\n","Successfully generated 10 new entries.\n","Total entries in dataset/data.jsonl: 10\n"]}]}]}