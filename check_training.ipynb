{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19402,
     "status": "ok",
     "timestamp": 1756446324885,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "xUkZn01uWKsH",
    "outputId": "f5fc2683-03da-4255-de07-7f40332d9abd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/My Drive/DLAA_2025/qwen2.5-0.5b-instruct-lora-output\n",
      "\u001b[0m\u001b[01;34mcheckpoint-20\u001b[0m/  evaluation_avant.json          evaluation_checkpoint-60.json\n",
      "\u001b[01;34mcheckpoint-40\u001b[0m/  evaluation_checkpoint-20.json  \u001b[01;34mplotdiag\u001b[0m/\n",
      "\u001b[01;34mcheckpoint-60\u001b[0m/  evaluation_checkpoint-40.json\n",
      "/content/drive/My Drive/DLAA_2025/qwen2.5-0.5b-instruct-lora-output\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd \"/content/drive/My Drive/DLAA_2025/qwen2.5-0.5b-instruct-lora-output\"\n",
    "%ls\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26559,
     "status": "ok",
     "timestamp": 1756446351448,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "7Vh17MEVXST8",
    "outputId": "0de32918-f21c-4c5d-95cf-3cfd3ed3c394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function abspath at 0x79cf34c860c0>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Add parent directory to sys.path\n",
    "print(os.path.abspath)\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "#from ts_dataset import ask_noimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1756446351449,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "XsDTLzEeZRwo"
   },
   "outputs": [],
   "source": [
    "# Create the directory if it does not exist\n",
    "output_dir = 'plotdiag'\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491,
     "referenced_widgets": [
      "e8ef81993d4d48a3afec57bc94481aac",
      "43b77bed57e74977baaa5f1f430ece28",
      "559bc0ef48784df7b5b5a75b3dddd756",
      "f87191adb6e44ae5a9d1d54a9f6de8c2",
      "8de7e7b9433e4d8ea67c53623438806a",
      "ab8d90ef872b42ee868f2386db876611",
      "647e79a7702d41a48681329d3c223cfd",
      "f990925e05e24e96906eb4f42e889d0d",
      "7628249e0d514c5f9aa01f1a984c89a5",
      "f2c0ef121ed14a18bb27764c5214fd85",
      "8c673d891afc4bc19fdf480393772032",
      "99bdc84d285a4051a2ec0f08a1e30e23",
      "f90349c4f3cb401ab48f5cfb13ea048d",
      "60e771b5233d466384fb26c344c4d548",
      "5e47f6e2a3c740179568d52ed4e5546f",
      "d50450c6376147328650f4cb8fd8ff94",
      "a641ca1b15504334a4811c808469090d",
      "1e4a58881a1f49549e1514b887c6897f",
      "249a5d424f814369a5946bf0cb949541",
      "37980bffe9a94007b70983146008185d",
      "20599fa49b484a69bb87e303c656a983",
      "b6ee9bea452d40bdb0649b0ec662382f",
      "ad1755c285b6481c8107940df48a81b3",
      "ab6e02802f844c0dabe9aee9c5af85b4",
      "a2aaacc892df4e5b8f3e13e11bd92b7d",
      "dd99579a2d134855be54f419daf9ffb4",
      "2cb205fd334d4c4ab3048068c8b5da4a",
      "9ea5884f8348436f800b61d334a77323",
      "4cb9cae154d14cceba17dbcbf7194b4e",
      "3582d7b316c24b0097d17c22df68834c",
      "2225aacf29254bebb24d6295f27a15db",
      "b46cccc12f2b4c989d0752cf36066669",
      "3782d9e9cf7c4ba69534ad4062eb377e",
      "ffe786b51cde4742b3dce2f0944e8909",
      "f40b9cf5923642d8a1a61e7f90b7ce26",
      "06ff36dac1a94e9cb1e65e1262a28ebf",
      "d364b5e31f684b4eafee5196939203bc",
      "e7044f5e7f9549c8aa87fec497e9ff1d",
      "10e3f5a6e9a34fa28e73a0334d702595",
      "2de2565002a94abca7adf0b62464c28d",
      "95120722e47b44eb9ed0f1bf84d987c0",
      "ae567a4ff28449e7b89fcfbd8ea5d0fe",
      "02d8b1edbda640ecb6a6117ad12fb740",
      "b36c076f6ee74142bddd2663643e959a",
      "431dfae1dc92445fa8a5b9d6b97e45a7",
      "02384956bf874714acf8cc2fba4e59b5",
      "cf084549825847e6b1e04b5714a83a24",
      "a6f46d3cee2b4c88a7a1020953a20386",
      "a5faadd804d048d690c7359f64e2da8b",
      "da016f8fda2845c48c80f790251ce2a9",
      "98e90900bce944ddb77a3971d9b861fe",
      "cf0ed4ccf50e47dfa6c89ba5c1b81afa",
      "2a6bdc0022494bae9736f943e629fe77",
      "a4d898df5b454914892bb809780a897f",
      "38686c6fcd2c46c597750b1c5d384129",
      "157f5b95021144a5a58102397abbe4ef",
      "f17570c2f2764b2288c487e26d999e93",
      "fc2df277a24c42f2b66fafdce7dc59db",
      "a0b4e96ebb534beda8803cdc9c6d7f63",
      "f3e555bb4e124e23a394fdd07b02d498",
      "574f3209e55940b0aa254528b17f26af",
      "88c761afdc944e1ca30cdb2fdf1907b0",
      "389daf3f58044b3c8e89e3681300c866",
      "321f6951b9b643cab8df3d9519329e74",
      "15797ae2f337444da5b0a72d2fb1767c",
      "dc105bbcca06459ebf6829e58581226a",
      "e1276dab22584a17a8527da61519740c",
      "900102f00007499eb18c0bfc96d3f338",
      "bb2002cd2953434eb3d48f3ba4e7c4c1",
      "d9bf80c7fcfc4067b20cbc30ed16d108",
      "1708640ef53e4b558c20437f30037ed5",
      "309a85ecbc4d4f1ba9799154c81bb802",
      "9bdd1954a4f7449eb34d1fde2f41d91b",
      "01911cf4b40247fa97cc38e01a0c174d",
      "2142d65e153f4424821f94b91050b263",
      "0b5846eef7ec4581a7d77c960efc509f",
      "da9e2eeb10eb400382b059f535188bfb",
      "15db05ca678348bcabafd8d3e0ff6b63",
      "e2ec0459729149569cf4ca1328a573f7",
      "1a631f2fef1e41ffa916bbbd744d839f",
      "ad1c48c9cb964283850a332a1c4e6f3a",
      "9e182aca10fe4d0997328ecaf3f5495d",
      "bd8a1005594842f59de853fcee51c929",
      "462d7b44c9b64152ad037143db004b95",
      "de1de1d7cb24491481cf239dcac32256",
      "bb3c1389dbde41c5befcade310054d74",
      "a371b5d6602a4bfab1da06205071c5a8",
      "3bd677c5aa114e57b2ab65095f7b996a",
      "9db6c5cc4cb5407cbe4c0a1a5b10bfb1",
      "2c1a11faaad44986b0190b2ed098be01",
      "c9eed824ec2f4e7e929fbe11267b635b",
      "a79bc5e63c834f7da974fab2e3cb183b",
      "7ef716e5020b4409856d2e7cfbcf2a72",
      "dbc97306e25449b098eb11dbf4617d8a",
      "fdc52595073843ba866370e67864cb77",
      "2ce6678150a9418590da7d3a98bd49dd",
      "1a29159bf9b34712aa85dbddca239c8c",
      "d9f87cfa7a5f455f91641c88c145504e",
      "2c653f7310104348873c4a4497593bd6",
      "5078cc03ff2440e882d97eac9dbb1230",
      "50e3f8eb19ff4f5eb2c925abb1e27f8c",
      "bed319431e3e44a49e78cf65f737ae44",
      "0b0df209e80648f4ad213aa2ed6a77f5",
      "b1253823999f4832918daec11dee9375",
      "528d99856e3b426a9aea13fbaf3dd7ff",
      "afb5e8934e4149a6b960b8a134f2a825",
      "7d6f7e6a78f84f759e035941310f47b5",
      "32d8b71fbc79464c83d47a336e70b625",
      "ba48db6cd30349f7ab0f28ca917b7c47",
      "ff154a7002154d018b4e19e015cbeb5f",
      "7fa639b4d17c49e9afcde5848b65f5c9",
      "3f285fc7bf6443f7a8b11149c55180df",
      "fc8cdb85de1b4fe1b3686b551cf900f8",
      "58ea1ad7534749c5994e2118fb1d6a8e",
      "4156c748f17840a6ab8b48e757f5391f",
      "261089e03ac34a13989a6ca306375333",
      "93c7ddd49ed54fab9f802111dcaab1df",
      "8b7457885e434689adef5f61be67cf63",
      "cd6e5944862c4ca79c90b2005b100905",
      "c9962d19704e432fa00a80d9944c8d14",
      "bc1c5da8e928449d927e759786db72e7"
     ]
    },
    "executionInfo": {
     "elapsed": 4228,
     "status": "ok",
     "timestamp": 1756446355678,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "7AJ_yq7raSsK",
    "outputId": "c7ad9f20-b91b-4793-e0b5-c9ef7cae67f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model paraphrase-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ef81993d4d48a3afec57bc94481aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bdc84d285a4051a2ec0f08a1e30e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad1755c285b6481c8107940df48a81b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe786b51cde4742b3dce2f0944e8909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431dfae1dc92445fa8a5b9d6b97e45a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157f5b95021144a5a58102397abbe4ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1276dab22584a17a8527da61519740c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15db05ca678348bcabafd8d3e0ff6b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db6c5cc4cb5407cbe4c0a1a5b10bfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5078cc03ff2440e882d97eac9dbb1230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa639b4d17c49e9afcde5848b65f5c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load sentence transformer model\n",
    "model_name = \"paraphrase-MiniLM-L6-v2\"\n",
    "print(\"Loading model \" + model_name)\n",
    "model_st = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316,
     "referenced_widgets": [
      "7045665fd17c4e9cb8240ef4585a9a3d",
      "40c1f7933dc445b2927cd4c46a354ae2",
      "2faed1ed38b84336828ed8570b046cc0",
      "bfdf8f0ae0ef410080a22120bbbeb776",
      "33502176891249d296521bc71bf1314d",
      "e102b4a07063432e9ebe5e0e6be280ac",
      "19f117b3c2d44d5ab01a7234419430b8",
      "d632fc7a8f6a4a4d81a10315494c1b51",
      "b63f339b146f4294843a4109c8439a59",
      "9889879e617a4838a6e046fec6a0de6d",
      "15f737a4686c47399a8864876b3bfcd0",
      "805c1bc661f64700a77d6b3d03bfe53d",
      "09f0b64bed48498c8990c21b1b2784b2",
      "a0cd8a3179c7443db48a55717181c56a",
      "d4eb370c98204364ab083d9004eb2c92",
      "07c03281826744f1ba45763ce7cfd426",
      "f3a1d5470c234ec39a3eab0dc8f95865",
      "77b6dfca99e0432984272ee503bae53e",
      "b92b2ee279504438a3136a23eeb9af4b",
      "de1df142986447f0bab9d4bd8a4e40e6",
      "1f37c00927e64b3e8e91b96423982c68",
      "0f62c1dd37e94bff910b4953a16dcbeb",
      "5e5b692e67424873914d6f40e5307754",
      "f8f065f9e5054f9fa694e19805040ea6",
      "ada4d97885d54816b243d5745cd2a0f1",
      "d781c78530954c928c137c24f0a896aa",
      "1795bb0c01194bacb650db012bcb7aa7",
      "7dd741bf162a401db19eaec7687b9fda",
      "51cb656abbd34e3b9367538f2399d875",
      "3e01982344e7422698b03f5bd3db3a2a",
      "8fc0792193054907b3cef224f8f95d5b",
      "da43c8bb93534a4cb36be4c563981073",
      "d03ff0ab3e64402595e78989a79c6ce0",
      "734af5a613d94b5eb9bd0c4a8d1293ca",
      "91a97b1776ac4b96be02a908e9415811",
      "17878a54a6f243b3b8cb64e3b8295464",
      "5e29561e367e47839db98947cbca6506",
      "14e2a6d14c2c4a128da5cc10fc33e5fb",
      "4031fb45eb0340aab7653fc68807d25a",
      "bb82f7e067c94adf9993ff12735e5cc9",
      "4f2886d74b1647eca3fbeb8ac27c9496",
      "7ece592b55f544daa6ff7d23205f7f45",
      "02259bcabfba447b9c5d21341cb43f3f",
      "19ba7df273864608a7e4f7de36272770",
      "10a1eaeef70c442db327397335eafc7a",
      "0fe90205aefd41a983b5019376a5d3d0",
      "a33704f6ca514a1ab094609d5ba3e076",
      "667ef0890b0641ffa51b3e4d3317b0b6",
      "ec41e533a7a844f3864f1fc68cfee762",
      "c07954f05d5d482182d7859af428f6e0",
      "7ec711f5b7474063b6b5175532af6495",
      "327f199bf780455b92d64e3b9ee4e44d",
      "0f92e1429eb24dcca97dadd6b9b85839",
      "efd71eafa3214068b39da781fd3b2ad3",
      "f195938346854271a744f5dd4d11d5be",
      "433f9375fa394ba2bb4e07135e7ebe45",
      "cef77c9e1d2744e58f8508727f082ebf",
      "38effde1784c422488e5fb8833edfcd3",
      "edb6b35358d8499191c23a59b189dbde",
      "0c58158a7f3540ddac018b2b5809e415",
      "d6c1d7add7d34a63b711dc13f4ef203c",
      "2ef484ec30b7460b84384ed53d99e8d2",
      "2a55dc8ecb0649649a6b98afe99ce097",
      "9e1b3b01177f42ed868e1c9d2bd0d5ba",
      "f6338d38229f4f53a1285a0cb647e6e4",
      "788aac092150438ca5ce3c09c08c83e4"
     ]
    },
    "executionInfo": {
     "elapsed": 26205,
     "status": "ok",
     "timestamp": 1756446381891,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "zuwqJnYYaYSp",
    "outputId": "e3cc731d-6184-45ca-cfaf-fc5e6646586d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NLI model roberta-large-mnli\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7045665fd17c4e9cb8240ef4585a9a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805c1bc661f64700a77d6b3d03bfe53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/688 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5b692e67424873914d6f40e5307754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734af5a613d94b5eb9bd0c4a8d1293ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a1eaeef70c442db327397335eafc7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433f9375fa394ba2bb4e07135e7ebe45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: no, Score: 0.9918491840362549\n"
     ]
    }
   ],
   "source": [
    "# Load a model trained for contradiction detection (NLI)\n",
    "nli_model_name = \"roberta-large-mnli\"\n",
    "print(\"Loading NLI model \" + nli_model_name)\n",
    "nli_tokenizer = AutoTokenizer.from_pretrained(nli_model_name)\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(nli_model_name)\n",
    "\n",
    "def compute_semantic_similarity(gold_output, generated_output):\n",
    "    emb_generated = model_st.encode([generated_output], convert_to_tensor=True)\n",
    "    emb_gold = model_st.encode([gold_output], convert_to_tensor=True)\n",
    "\n",
    "    cosine_score = torch.nn.functional.cosine_similarity(emb_generated, emb_gold).cpu().item()\n",
    "    euclidean_score = euclidean_distances(emb_generated.cpu(), emb_gold.cpu())[0][0]\n",
    "\n",
    "    return cosine_score, euclidean_score\n",
    "\n",
    "def detect_contradiction_nli(premise, hypothesis):\n",
    "    inputs = nli_tokenizer.encode_plus(premise, hypothesis, return_tensors='pt', truncation=True)\n",
    "    with torch.no_grad():\n",
    "        logits = nli_model(**inputs).logits\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    #labels = ['entailment', 'neutral', 'contradiction']\n",
    "    labels = ['no', 'bof', 'ok']\n",
    "    max_idx = torch.argmax(probs).item()\n",
    "    return labels[max_idx], probs[0][max_idx].item()\n",
    "\n",
    "\n",
    "# test the detection of contradiction\n",
    "premise = \"The cat is in the tree.\"\n",
    "hypothesis = \"The moggy is swimming.\"\n",
    "label, score = detect_contradiction_nli(premise, hypothesis)\n",
    "print(f\"Label: {label}, Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 552,
     "status": "ok",
     "timestamp": 1756446382440,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "fkP-_nbga1LZ"
   },
   "outputs": [],
   "source": [
    "file_name = 'evaluation_checkpoint-40.json'\n",
    "#file_name = 'evaluation_avant.json'\n",
    "# Load the specified JSON file\n",
    "with open(file_name, 'r') as f:\n",
    "    evaluation_apres = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1756446382470,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "-ZuA-wYXdK83"
   },
   "outputs": [],
   "source": [
    "# compute verified annotations from ground truth\n",
    "def ask_truth(X):\n",
    "    x = np.arange(len(X))\n",
    "    coeffs = np.polyfit(x, X, deg=3)\n",
    "    P = np.poly1d(coeffs)\n",
    "    X_fit = P(x)\n",
    "    # compute the l2 norm of the difference\n",
    "    l2_norm = np.linalg.norm(X - X_fit)/np.sqrt(len(X))\n",
    "    # plt.plot(x,X)\n",
    "    # plt.plot(x,X_fit)\n",
    "    # plt.show()\n",
    "    Pp = P.deriv()\n",
    "    Xp_fit = Pp(x)\n",
    "    delta = Xp_fit[-1] - Xp_fit[0]\n",
    "    # divmin = np.min(Xp_fit)\n",
    "    # divmax = np.max(Xp_fit)\n",
    "    # if divmin > 0:\n",
    "    #     sentence =  \"the time series presents an overall increasing trend\"\n",
    "    # elif divmax < 0:\n",
    "    #     sentence = \"the time series presents an overall decreasing trend\"\n",
    "    # else:\n",
    "    #     sentence = \"the time series presents no uniformly increasing or decreasing trend\"\n",
    "    # if delta > 5:\n",
    "    #     sentence =  \"the time series presents an overall increasing trend\"\n",
    "    # elif delta < -5:\n",
    "    #     sentence = \"the time series presents an overall decreasing trend\"\n",
    "    # else:\n",
    "    #     sentence = \"the time series presents no uniformly increasing or decreasing trend\"\n",
    "    # compute the average of the solution on the 20 first points\n",
    "    average1 = np.mean(X[:20])\n",
    "    # compute the average of the solution on the 20 last points\n",
    "    average2 = np.mean(X[-20:])\n",
    "    if average1 < average2 -3:\n",
    "        sentence_trend = \"the time series shows an overall increasing trend.\"\n",
    "    elif average1 > average2 +3:\n",
    "        sentence_trend = \"the time series shows an overall decreasing trend.\"\n",
    "    else:\n",
    "        sentence_trend = \"the time series shows no uniformly increasing or decreasing trend.\"\n",
    "\n",
    "    print(f\"L2 norm of the difference: {l2_norm}\")\n",
    "    #sentence_noise = self.data_json[i][\"description\"][\"noise\"]\n",
    "    if l2_norm < 2:\n",
    "        sentence_noise = \"the noise intensity is low\"\n",
    "    elif l2_norm > 12:\n",
    "        sentence_noise = \"the noise intensity is high\"\n",
    "    else:\n",
    "        sentence_noise = \"the noise intensity is medium\"\n",
    "    # print(sentence_noise)\n",
    "    # self.data_json[i][\"truth_description\"][\"noise\"] = sentence_noise\n",
    "    # recherche de la localisation en t du maximum et du minimum\n",
    "    pos_max = np.argmax(X)\n",
    "    print('pos_max', pos_max)\n",
    "    if pos_max < 32:\n",
    "        sentence_extrema = \"The maximum is reached around the beginning part of the time series\"\n",
    "    elif pos_max > 96:\n",
    "        sentence_extrema = \"The maximum is reached towards the end of the time series\"\n",
    "    else:\n",
    "        sentence_extrema = \"The maximum is reached around the middle of the time series\"\n",
    "\n",
    "    pos_min = np.argmin(X)\n",
    "    print('pos_min', pos_min)\n",
    "    if pos_min < 32:\n",
    "        sentence_extrema += \" and the minimum is reached around the beginning part of the time series.\"\n",
    "    elif pos_min > 96:\n",
    "        sentence_extrema += \" and the minimum is reached towards the end of the time series.\"\n",
    "    else:\n",
    "        sentence_extrema += \" and the minimum is reached around the middle of the time series.\"\n",
    "\n",
    "    return (sentence_trend, sentence_noise, sentence_extrema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 51,
     "status": "ok",
     "timestamp": 1756446382524,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "dv-XpXt8bkqR"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "import re\n",
    "def plot_and_save(i):\n",
    "    input_data = evaluation_apres[i]['input']\n",
    "    series_str = input_data.split('Series: ')[1].strip()\n",
    "    series_str = re.sub(r'\\b0+(\\d)', r'\\1', series_str)\n",
    "    series = ast.literal_eval(series_str)\n",
    "\n",
    "\n",
    "    truth_trend, truth_noise, truth_extrema = ask_truth(series)\n",
    "    print(\"truth_trend: \", truth_trend)\n",
    "    print(\"truth_noise: \", truth_noise)\n",
    "    print(\"truth_extrema: \", truth_extrema)\n",
    "    #series = json.loads(input_data.split('Series: ')[1])\n",
    "    #exit()\n",
    "    gold_output = evaluation_apres[i]['gold_output']\n",
    "    # diagnostic_avant = evaluation_avant[i]['generated_output']\n",
    "    # cute the string to the first 600 characters\n",
    "    # diagnostic_avant = diagnostic_avant[:600]\n",
    "    diagnostic_apres = evaluation_apres[i]['generated_output']\n",
    "    print(\"diagnostic_apres: \", diagnostic_apres)\n",
    "    # in this string keep the string that is between { }\n",
    "    diagnostic_apres = diagnostic_apres[diagnostic_apres.find('{'):diagnostic_apres.rfind('}')+1]\n",
    "    print(\"diagnostic_apres: \", diagnostic_apres)\n",
    "\n",
    "    sentence_gold = []\n",
    "    sentence_after = []\n",
    "\n",
    "    # extract json object from the string before\n",
    "    json_gold = json.loads(gold_output)\n",
    "    sentence_gold.append(json_gold['trend'])\n",
    "    sentence_gold.append(json_gold['noise'])\n",
    "    sentence_gold.append(json_gold['extrema'])\n",
    "\n",
    "    sentence_gold = [truth_trend, truth_noise, truth_extrema]\n",
    "\n",
    "    try:\n",
    "        json_after = json.loads(diagnostic_apres)\n",
    "        print(\"json_after: \", json_after)\n",
    "        sentence_after.append(json_after['trend'])\n",
    "        sentence_after.append(json_after['noise'])\n",
    "        sentence_after.append(json_after['extrema'])\n",
    "        print(\"sentence_after: \", sentence_after)\n",
    "    except (json.JSONDecodeError, KeyError):\n",
    "        sentence_after.extend([\"\"] * 3)\n",
    "\n",
    "    print(\"sentence_after: \", sentence_after)\n",
    "\n",
    "\n",
    "    # Compute similarity scores for each sentence\n",
    "    print(f\"Calculating similarity scores for entry {i}...\")\n",
    "    cosine_score_gold, euclidean_score_gold = [] , []\n",
    "    cosine_score_apres, euclidean_score_apres = [] , []\n",
    "    cass_label_gold, cass_score_gold = [] , []\n",
    "    cass_label_apres, cass_score_apres = [] , []\n",
    "    # for each sentence in the json object\n",
    "    for iss in range(len(sentence_gold)):\n",
    "        # Ensure inputs are strings\n",
    "        after_text = str(sentence_after[iss]) if not isinstance(sentence_after[iss], str) else sentence_after[iss]\n",
    "        gold_text = str(sentence_gold[iss]) if not isinstance(sentence_gold[iss], str) else sentence_gold[iss]\n",
    "\n",
    "        a , b = compute_semantic_similarity(after_text, gold_text)\n",
    "        print(after_text, gold_text, a,b)\n",
    "        cosine_score_apres.append(a)\n",
    "        euclidean_score_apres.append(b)\n",
    "        a,b = detect_contradiction_nli(after_text, gold_text)\n",
    "        cass_label_apres.append(a)\n",
    "        cass_score_apres.append(b)\n",
    "\n",
    "    # Concatenate the similarity scores and CASS labels properly\n",
    "    for cosine, euclidean, cass_label, cass_score in zip(cosine_score_apres, euclidean_score_apres, cass_label_apres, cass_score_apres):\n",
    "        diagnostic_apres += f\"\\n\\nCosine Score: {cosine:.4f}\\nEuclidean Distance: {euclidean:.4f}\"\n",
    "        diagnostic_apres += f\"\\n\\n[CASS] Relation: {cass_label} (score: {cass_score:.4f})\"\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(1+3, 1, figsize=(10, 12))\n",
    "    axs[0].set_ylim(0, 99)\n",
    "    axs[0].plot(series)\n",
    "    axs[0].set_xlabel('Time')\n",
    "    axs[0].set_ylabel('Value')\n",
    "    axs[0].set_title('Time Series')\n",
    "\n",
    "\n",
    "    for iss in range(len(sentence_gold)):\n",
    "        axs[1+iss].axis('off')\n",
    "        disp = 'gold: '+str(sentence_gold[iss]) + ' \\n' + 'after: ' + str(sentence_after[iss]) + ' \\n' + 'cosine: ' + str(cosine_score_apres[iss]) + ' \\n' + 'euclidean: ' + str(euclidean_score_apres[iss]) + ' \\n' + 'cass: ' + cass_label_apres[iss] + ' \\n' + 'cass score: ' + str(cass_score_apres[iss])\n",
    "        color = 'red' if cass_label_apres[iss] == 'no' else 'orange' if cass_label_apres[iss] == 'bof' else 'green'\n",
    "        axs[1+iss].text(0.1, 0.5, disp, fontsize=10, verticalalignment='center', wrap=True, color=color)\n",
    "\n",
    "    # color_avant = 'red' if cass_label_gold == 'contradiction' else 'orange' if cass_label_gold == 'neutral' else 'blue'\n",
    "    # color_apres = 'red' if cass_label_apres == 'contradiction' else 'orange' if cass_label_apres == 'neutral' else 'green'\n",
    "\n",
    "    # axs[2].axis('off')\n",
    "    # axs[2].text(0.1, 0.5, diagnostic_avant, fontsize=10, verticalalignment='center', wrap=True, color=color_avant)\n",
    "\n",
    "    # axs[2].axis('off')\n",
    "    # axs[2].text(0.1, 0.5, diagnostic_apres, fontsize=10, verticalalignment='center', wrap=True, color=color_apres)\n",
    "\n",
    "    fig.suptitle(f'Case number {i}', fontsize=16)\n",
    "    file_name = os.path.join(output_dir, f'case_{i}.png')\n",
    "    print(f\"Saving figure to {file_name}\")\n",
    "    fig.savefig(file_name)\n",
    "    plt.close(fig)\n",
    "    scores = [0 if ca == 'no' else 1 if ca == 'ok' else 0.5 for ca in cass_label_apres]\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19785,
     "status": "ok",
     "timestamp": 1756446402307,
     "user": {
      "displayName": "Philippe Helluy",
      "userId": "07790988964707423334"
     },
     "user_tz": -120
    },
    "id": "d9A9GOZcb5Q4",
    "outputId": "49e65fe2-47ef-4dd0-99f0-7f73d071b354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 norm of the difference: 11.104642775646\n",
      "pos_max 72\n",
      "pos_min 1\n",
      "truth_trend:  the time series shows an overall increasing trend.\n",
      "truth_noise:  the noise intensity is medium\n",
      "truth_extrema:  The maximum is reached around the middle of the time series and the minimum is reached around the beginning part of the time series.\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall increasing trend.\", \"noise\": \"The noise intensity is medium\", \"extrema\": \"The global maximum is located towards the end, while the global minimum is at the beginning.\"}\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall increasing trend.\", \"noise\": \"The noise intensity is medium\", \"extrema\": \"The global maximum is located towards the end, while the global minimum is at the beginning.\"}\n",
      "json_after:  {'trend': 'The time series shows an overall increasing trend.', 'noise': 'The noise intensity is medium', 'extrema': 'The global maximum is located towards the end, while the global minimum is at the beginning.'}\n",
      "sentence_after:  ['The time series shows an overall increasing trend.', 'The noise intensity is medium', 'The global maximum is located towards the end, while the global minimum is at the beginning.']\n",
      "sentence_after:  ['The time series shows an overall increasing trend.', 'The noise intensity is medium', 'The global maximum is located towards the end, while the global minimum is at the beginning.']\n",
      "Calculating similarity scores for entry 0...\n",
      "The time series shows an overall increasing trend. the time series shows an overall increasing trend. 0.9999998807907104 0.0\n",
      "The noise intensity is medium the noise intensity is medium 1.0 0.0\n",
      "The global maximum is located towards the end, while the global minimum is at the beginning. The maximum is reached around the middle of the time series and the minimum is reached around the beginning part of the time series. 0.5945677757263184 4.6827354\n",
      "Saving figure to plotdiag/case_0.png\n",
      "Scores for case 0: [1, 1, 1]\n",
      "L2 norm of the difference: 2.2216955452186005\n",
      "pos_max 123\n",
      "pos_min 0\n",
      "truth_trend:  the time series shows an overall increasing trend.\n",
      "truth_noise:  the noise intensity is medium\n",
      "truth_extrema:  The maximum is reached towards the end of the time series and the minimum is reached around the beginning part of the time series.\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall increasing trend over the entire period.\", \"noise\": \"The noise intensity is medium, with noticeable fluctuations throughout the series.\", \"extrema\": \"The global maximum is located at the end, while the global minimum is situated towards the beginning.\"}\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall increasing trend over the entire period.\", \"noise\": \"The noise intensity is medium, with noticeable fluctuations throughout the series.\", \"extrema\": \"The global maximum is located at the end, while the global minimum is situated towards the beginning.\"}\n",
      "json_after:  {'trend': 'The time series shows an overall increasing trend over the entire period.', 'noise': 'The noise intensity is medium, with noticeable fluctuations throughout the series.', 'extrema': 'The global maximum is located at the end, while the global minimum is situated towards the beginning.'}\n",
      "sentence_after:  ['The time series shows an overall increasing trend over the entire period.', 'The noise intensity is medium, with noticeable fluctuations throughout the series.', 'The global maximum is located at the end, while the global minimum is situated towards the beginning.']\n",
      "sentence_after:  ['The time series shows an overall increasing trend over the entire period.', 'The noise intensity is medium, with noticeable fluctuations throughout the series.', 'The global maximum is located at the end, while the global minimum is situated towards the beginning.']\n",
      "Calculating similarity scores for entry 1...\n",
      "The time series shows an overall increasing trend over the entire period. the time series shows an overall increasing trend. 0.9312617182731628 2.2190232\n",
      "The noise intensity is medium, with noticeable fluctuations throughout the series. the noise intensity is medium 0.827849268913269 4.0194902\n",
      "The global maximum is located at the end, while the global minimum is situated towards the beginning. The maximum is reached towards the end of the time series and the minimum is reached around the beginning part of the time series. 0.6003236770629883 4.6264496\n",
      "Saving figure to plotdiag/case_1.png\n",
      "Scores for case 1: [1, 1, 1]\n",
      "L2 norm of the difference: 6.263788719166614\n",
      "pos_max 1\n",
      "pos_min 127\n",
      "truth_trend:  the time series shows an overall decreasing trend.\n",
      "truth_noise:  the noise intensity is medium\n",
      "truth_extrema:  The maximum is reached around the beginning part of the time series and the minimum is reached towards the end of the time series.\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall decreasing trend over time.\", \"noise\": \"The noise intensity is medium, with noticeable fluctuations throughout the data.\", \"extrema\": \"The global maximum is located at the beginning, while the global minimum is towards the end.\"}\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall decreasing trend over time.\", \"noise\": \"The noise intensity is medium, with noticeable fluctuations throughout the data.\", \"extrema\": \"The global maximum is located at the beginning, while the global minimum is towards the end.\"}\n",
      "json_after:  {'trend': 'The time series shows an overall decreasing trend over time.', 'noise': 'The noise intensity is medium, with noticeable fluctuations throughout the data.', 'extrema': 'The global maximum is located at the beginning, while the global minimum is towards the end.'}\n",
      "sentence_after:  ['The time series shows an overall decreasing trend over time.', 'The noise intensity is medium, with noticeable fluctuations throughout the data.', 'The global maximum is located at the beginning, while the global minimum is towards the end.']\n",
      "sentence_after:  ['The time series shows an overall decreasing trend over time.', 'The noise intensity is medium, with noticeable fluctuations throughout the data.', 'The global maximum is located at the beginning, while the global minimum is towards the end.']\n",
      "Calculating similarity scores for entry 2...\n",
      "The time series shows an overall decreasing trend over time. the time series shows an overall decreasing trend. 0.9710760116577148 1.6082431\n",
      "The noise intensity is medium, with noticeable fluctuations throughout the data. the noise intensity is medium 0.8243393898010254 4.0415654\n",
      "The global maximum is located at the beginning, while the global minimum is towards the end. The maximum is reached around the beginning part of the time series and the minimum is reached towards the end of the time series. 0.5945139527320862 4.720026\n",
      "Saving figure to plotdiag/case_2.png\n",
      "Scores for case 2: [1, 1, 1]\n",
      "L2 norm of the difference: 6.235230027718213\n",
      "pos_max 127\n",
      "pos_min 0\n",
      "truth_trend:  the time series shows an overall increasing trend.\n",
      "truth_noise:  the noise intensity is medium\n",
      "truth_extrema:  The maximum is reached towards the end of the time series and the minimum is reached around the beginning part of the time series.\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall increasing trend.\", \"noise\": \"The noise intensity is medium, with noticeable fluctuations throughout.\", \"extrema\": \"The global maximum is located towards the end, while the global minimum is situated at the beginning.\"}\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall increasing trend.\", \"noise\": \"The noise intensity is medium, with noticeable fluctuations throughout.\", \"extrema\": \"The global maximum is located towards the end, while the global minimum is situated at the beginning.\"}\n",
      "json_after:  {'trend': 'The time series shows an overall increasing trend.', 'noise': 'The noise intensity is medium, with noticeable fluctuations throughout.', 'extrema': 'The global maximum is located towards the end, while the global minimum is situated at the beginning.'}\n",
      "sentence_after:  ['The time series shows an overall increasing trend.', 'The noise intensity is medium, with noticeable fluctuations throughout.', 'The global maximum is located towards the end, while the global minimum is situated at the beginning.']\n",
      "sentence_after:  ['The time series shows an overall increasing trend.', 'The noise intensity is medium, with noticeable fluctuations throughout.', 'The global maximum is located towards the end, while the global minimum is situated at the beginning.']\n",
      "Calculating similarity scores for entry 3...\n",
      "The time series shows an overall increasing trend. the time series shows an overall increasing trend. 0.9999998807907104 0.0\n",
      "The noise intensity is medium, with noticeable fluctuations throughout. the noise intensity is medium 0.8590943813323975 3.6421213\n",
      "The global maximum is located towards the end, while the global minimum is situated at the beginning. The maximum is reached towards the end of the time series and the minimum is reached around the beginning part of the time series. 0.603948175907135 4.6453624\n",
      "Saving figure to plotdiag/case_3.png\n",
      "Scores for case 3: [1, 1, 1]\n",
      "L2 norm of the difference: 13.844031032791879\n",
      "pos_max 109\n",
      "pos_min 77\n",
      "truth_trend:  the time series shows an overall increasing trend.\n",
      "truth_noise:  the noise intensity is high\n",
      "truth_extrema:  The maximum is reached towards the end of the time series and the minimum is reached around the middle of the time series.\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall increasing trend over the observed period.\", \"noise\": \"The noise intensity is medium, with noticeable fluctuations around the trend line.\", \"extrema\": \"The global maximum is located towards the end of the time series, while the global minimum is situated at the beginning.\"}\n",
      "diagnostic_apres:  {\"trend\": \"The time series shows an overall increasing trend over the observed period.\", \"noise\": \"The noise intensity is medium, with noticeable fluctuations around the trend line.\", \"extrema\": \"The global maximum is located towards the end of the time series, while the global minimum is situated at the beginning.\"}\n",
      "json_after:  {'trend': 'The time series shows an overall increasing trend over the observed period.', 'noise': 'The noise intensity is medium, with noticeable fluctuations around the trend line.', 'extrema': 'The global maximum is located towards the end of the time series, while the global minimum is situated at the beginning.'}\n",
      "sentence_after:  ['The time series shows an overall increasing trend over the observed period.', 'The noise intensity is medium, with noticeable fluctuations around the trend line.', 'The global maximum is located towards the end of the time series, while the global minimum is situated at the beginning.']\n",
      "sentence_after:  ['The time series shows an overall increasing trend over the observed period.', 'The noise intensity is medium, with noticeable fluctuations around the trend line.', 'The global maximum is located towards the end of the time series, while the global minimum is situated at the beginning.']\n",
      "Calculating similarity scores for entry 4...\n",
      "The time series shows an overall increasing trend over the observed period. the time series shows an overall increasing trend. 0.9411351680755615 2.0842757\n",
      "The noise intensity is medium, with noticeable fluctuations around the trend line. the noise intensity is high 0.7298167943954468 4.799963\n",
      "The global maximum is located towards the end of the time series, while the global minimum is situated at the beginning. The maximum is reached towards the end of the time series and the minimum is reached around the middle of the time series. 0.7549529671669006 3.4819262\n",
      "Saving figure to plotdiag/case_4.png\n",
      "Scores for case 4: [1, 0, 0]\n",
      "Mean scores: [1.0, 0.8, 0.8]\n"
     ]
    }
   ],
   "source": [
    "mean_scores = [0.,0.,0.]\n",
    "for i in range(len(evaluation_apres)):\n",
    "  scores = plot_and_save(i)\n",
    "  print(f\"Scores for case {i}: {scores}\")\n",
    "  for j in range(3):\n",
    "    mean_scores[j] += scores[j]\n",
    "for j in range(3):\n",
    "  mean_scores[j] /= len(evaluation_apres)\n",
    "print(f\"Mean scores: {mean_scores}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
